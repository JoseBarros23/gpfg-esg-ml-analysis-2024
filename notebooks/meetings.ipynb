{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0f513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b9edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed ESG and Holdings data\n",
    "DATA_PATH = \"../datasets/\"\n",
    "fund2024 =pd.read_parquet(DATA_PATH +'fund_esg_2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee9b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8645 entries, 0 to 8644\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Industry          8645 non-null   object \n",
      " 1   Region            8645 non-null   object \n",
      " 2   Country           8645 non-null   object \n",
      " 3   Name              8645 non-null   object \n",
      " 4   Market_Value_USD  8645 non-null   int64  \n",
      " 5   Voting            8645 non-null   float64\n",
      " 6   Ownership         8645 non-null   float64\n",
      " 7   Portfolio_Weight  8645 non-null   float64\n",
      " 8   Environmental     8645 non-null   int32  \n",
      " 9   Social            8645 non-null   int32  \n",
      " 10  Governance        8645 non-null   int32  \n",
      " 11  Climate_change    8645 non-null   int32  \n",
      " 12  ESG_any           8645 non-null   int32  \n",
      "dtypes: float64(3), int32(5), int64(1), object(4)\n",
      "memory usage: 709.3+ KB\n"
     ]
    }
   ],
   "source": [
    "fund2024.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8647a402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market_Value_USD</th>\n",
       "      <th>Voting</th>\n",
       "      <th>Ownership</th>\n",
       "      <th>Portfolio_Weight</th>\n",
       "      <th>Environmental</th>\n",
       "      <th>Social</th>\n",
       "      <th>Governance</th>\n",
       "      <th>Climate_change</th>\n",
       "      <th>ESG_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Germany</td>\n",
       "      <td>jost werke se</td>\n",
       "      <td>24264354</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>Industrials</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>beacon roofing supply inc</td>\n",
       "      <td>94573418</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Industry         Region        Country  \\\n",
       "1298  Consumer Discretionary         Europe        Germany   \n",
       "4906             Industrials  North America  United States   \n",
       "\n",
       "                           Name  Market_Value_USD  Voting  Ownership  \\\n",
       "1298              jost werke se          24264354    3.46       3.46   \n",
       "4906  beacon roofing supply inc          94573418    1.50       1.50   \n",
       "\n",
       "      Portfolio_Weight  Environmental  Social  Governance  Climate_change  \\\n",
       "1298          0.001887              0       0           0               0   \n",
       "4906          0.007355              0       0           0               0   \n",
       "\n",
       "      ESG_any  \n",
       "1298        0  \n",
       "4906        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund2024.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c616c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (5.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jose fernando barros\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy requests beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43314bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At top of notebook\n",
    "DATA_PATH = \"../datasets/\"\n",
    "TEMP_PATH = \"./temp/\"\n",
    "VOTING_DATA_PATH = \"../datasets/voting_data/\"\n",
    "\n",
    "# Load data\n",
    "df_p80 = pd.read_csv(DATA_PATH + 'p80_companies_sorted_with_status.csv')\n",
    "\n",
    "# Checkpoints will save to temp/\n",
    "checkpoint_file = TEMP_PATH + 'checkpoint_progress.csv'\n",
    "disagreements_file = TEMP_PATH + 'checkpoint_disagreements.csv'\n",
    "stats_file = TEMP_PATH + 'checkpoint_stats.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cacb47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P80 Market Value threshold: $81,794,677\n",
      "\n",
      "FINAL SAMPLE:\n",
      "Total companies: 1925\n",
      "\n",
      "Breakdown:\n",
      "  - P80 only (no ESG_any): 1024\n",
      "  - ESG_any only (outside P80): 196\n",
      "  - Both conditions (P80 AND ESG_any): 705\n",
      "\n",
      "ESG_any verification:\n",
      "  - Total ESG_any=1 in fund2024: 901\n",
      "  - ESG_any=1 in sample: 901\n",
      "  - ✓ All included: True\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# STEP 1: CREATE SAMPLE (P80 + ALL ESG_any=1)\n",
    "\n",
    "# Calculate P80\n",
    "p80_threshold = fund2024['Market_Value_USD'].quantile(0.80)\n",
    "\n",
    "print(f\"P80 Market Value threshold: ${p80_threshold:,.0f}\")\n",
    "\n",
    "# Create sample: P80 OR ESG_any=1 (union of both groups)\n",
    "df_p80 = fund2024[\n",
    "    (fund2024['Market_Value_USD'] >= p80_threshold) | \n",
    "    (fund2024['ESG_any'] == 1)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nFINAL SAMPLE:\")\n",
    "print(f\"Total companies: {len(df_p80)}\")\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  - P80 only (no ESG_any): {((fund2024['Market_Value_USD'] >= p80_threshold) & (fund2024['ESG_any'] == 0)).sum()}\")\n",
    "print(f\"  - ESG_any only (outside P80): {((fund2024['Market_Value_USD'] < p80_threshold) & (fund2024['ESG_any'] == 1)).sum()}\")\n",
    "print(f\"  - Both conditions (P80 AND ESG_any): {((fund2024['Market_Value_USD'] >= p80_threshold) & (fund2024['ESG_any'] == 1)).sum()}\")\n",
    "\n",
    "# Verification: all ESG_any=1 must be included\n",
    "total_esg_any = (fund2024['ESG_any'] == 1).sum()\n",
    "esg_any_in_sample = (df_p80['ESG_any'] == 1).sum()\n",
    "print(f\"\\nESG_any verification:\")\n",
    "print(f\"  - Total ESG_any=1 in fund2024: {total_esg_any}\")\n",
    "print(f\"  - ESG_any=1 in sample: {esg_any_in_sample}\")\n",
    "print(f\"  - ✓ All included: {total_esg_any == esg_any_in_sample}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "664272ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for reference\n",
    "df_p80.to_csv('p80_companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7698ea82",
   "metadata": {},
   "source": [
    "# API-Based Extraction of NBIM Voting Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e26dc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NBIM_API_KEY')\n",
    "BASE_URL = os.getenv('NBIM_BASE_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae50bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Query by company name (Microsoft)\n",
      "============================================================\n",
      "Status code: 200\n",
      "\n",
      "Response structure:\n",
      "{\n",
      "  \"companies\": [\n",
      "    {\n",
      "      \"Ticker\": \"MSFT\",\n",
      "      \"country\": \"United States\",\n",
      "      \"id\": 142533,\n",
      "      \"isin\": \"US5949181045\",\n",
      "      \"meetings\": [\n",
      "        {\n",
      "          \"meetingDate\": \"2025-12-05 00:00:00\",\n",
      "          \"meetingId\": 2017007,\n",
      "          \"meetingType\": \"Annual\"\n",
      "        },\n",
      "        {\n",
      "          \"meetingDate\": \"2024-12-10 00:00:00\",\n",
      "          \"meetingId\": 1906254,\n",
      "          \"meetingType\": \"Annual\"\n",
      "        },\n",
      "        {\n",
      "          \"meetingDate\": \"2023-12-07 00:00:00\",\n",
      "          \"meetingId\": 1798481,\n",
      "          \"meetingType\": \"Annual\"\n",
      "        },\n",
      "        {\n",
      "          \"meetingDate\": \"2022-12-13 00:00:00\",\n",
      "          \"meetingId\": 1694381,\n",
      "          \"meetingType\": \"Annual\"\n",
      "        },\n",
      "        {\n",
      "          \"meetingDate\": \"2021-11-30 00:00:00\",\n",
      "          \"meetingId\": 1584741,\n",
      "          \"meetingType\": \"Annual\"\n",
      "        },\n",
      "        {\n",
      "          \"meetingDate\": \"2020-12-02 00:00:00\",\n",
      "          \"meetingId\": 1479998,\n",
      "          \"meetingType\": \"Annual\"\n",
      "        },\n",
      "        {\n",
      "          \"meetingDate\": \"2\n",
      "\n",
      "✓ Full response saved to 'api_response_company.json'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# =============================================================================\n",
    "# API CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "API_KEY = \"bgvpKNCRTt9QyhHQMdXc86uhmSCKYDoL6BsyFQKC\"\n",
    "BASE_URL = \"https://vd.a.nbim.no\"\n",
    "\n",
    "headers = {\n",
    "    'x-api-key': API_KEY\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# EXPLORATION: TEST ENDPOINTS\n",
    "# =============================================================================\n",
    "\n",
    "# Test 1: Search by company name\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 1: Query by company name (Microsoft)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "company_name = \"microsoft corporation\"\n",
    "response = requests.get(\n",
    "    f\"{BASE_URL}/v1/query/company/{company_name}\",\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(f\"\\nResponse structure:\")\n",
    "    print(json.dumps(data, indent=2)[:1000])  # First 1000 chars\n",
    "    \n",
    "    # Save full response\n",
    "    with open('api_response_company.json', 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(\"\\n✓ Full response saved to 'api_response_company.json'\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d300699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 2: Query meeting details (ID: 2017007)\n",
      "============================================================\n",
      "Status code: 200\n",
      "\n",
      "Response structure:\n",
      "{\n",
      "  \"meeting\": {\n",
      "    \"companyId\": 142533,\n",
      "    \"companyName\": \"Microsoft Corporation\",\n",
      "    \"companyTicker\": \"MSFT\",\n",
      "    \"isin\": \"US5949181045\",\n",
      "    \"meetingDate\": \"2025-12-05 00:00:00\",\n",
      "    \"meetingId\": 2017007,\n",
      "    \"meetingType\": \"Annual\",\n",
      "    \"meetingVotes\": [\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732594,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1a\",\n",
      "        \"proposalSequence\": \"1\",\n",
      "        \"proposalText\": \"Elect Director Reid G. Hoffman\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732595,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1b\",\n",
      "        \"proposalSequence\": \"2\",\n",
      "        \"proposalText\": \"Elect Director Hugh F. Johnston\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732596,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1c\",\n",
      "        \"proposalSequence\": \"3\",\n",
      "        \"proposalText\": \"Elect Director Teri L. List\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732597,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1d\",\n",
      "        \"proposalSequence\": \"4\",\n",
      "        \"proposalText\": \"Elect Director Catherine MacGregor\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732598,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1e\",\n",
      "        \"proposalSequence\": \"5\",\n",
      "        \"proposalText\": \"Elect Director Mark A. L. Mason\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"globalVotingGuidelines\": \"https://www.nbim.no/en/responsible-investment/voting/global-voting-guidelines/\",\n",
      "        \"itemOnAgendaId\": 17732599,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1f\",\n",
      "        \"proposalSequence\": \"6\",\n",
      "        \"proposalText\": \"Elect Director Satya Nadella\",\n",
      "        \"voteInstruction\": \"Against\",\n",
      "        \"voterRationale\": [\n",
      "          {\n",
      "            \"positionPaper\": {\n",
      "              \"name\": \"Position paper: Separation of chairperson and CEO\",\n",
      "              \"url\": \"https://www.nbim.no/en/responsible-investment/position-papers/separation-of-chairperson-and-ceo/\"\n",
      "            },\n",
      "            \"publicRationaleOutgoing\": \"The board should exercise objective judgement on corporate affairs and be able to make decisions independently of management. The roles of chairperson and CEO should not be held by the same individual. Where a company founder combines both roles, we may support this for a limited period, provided the board has put in place measures to mitigate any conflicts of interest.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732600,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1g\",\n",
      "        \"proposalSequence\": \"7\",\n",
      "        \"proposalText\": \"Elect Director Sandra E. Peterson\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732601,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1h\",\n",
      "        \"proposalSequence\": \"8\",\n",
      "        \"proposalText\": \"Elect Director Penny S. Pritzker\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732602,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1i\",\n",
      "        \"proposalSequence\": \"9\",\n",
      "        \"proposalText\": \"Elect Director John David Rainey\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732603,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1j\",\n",
      "        \"proposalSequence\": \"10\",\n",
      "        \"proposalText\": \"Elect Director Charles W. Scharf\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732604,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1k\",\n",
      "        \"proposalSequence\": \"11\",\n",
      "        \"proposalText\": \"Elect Director John W. Stanton\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732605,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"1l\",\n",
      "        \"proposalSequence\": \"12\",\n",
      "        \"proposalText\": \"Elect Director Emma N. Walmsley\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"globalVotingGuidelines\": \"https://www.nbim.no/en/responsible-investment/voting/global-voting-guidelines/\",\n",
      "        \"itemOnAgendaId\": 17732606,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"2\",\n",
      "        \"proposalSequence\": \"13\",\n",
      "        \"proposalText\": \"Advisory Vote to Ratify Named Executive Officers' Compensation\",\n",
      "        \"voteInstruction\": \"Against\",\n",
      "        \"voterRationale\": [\n",
      "          {\n",
      "            \"positionPaper\": {\n",
      "              \"name\": \"Position paper: CEO remuneration\",\n",
      "              \"url\": \"http://www.nbim.no/en/the-fund/responsible-investment/position-papers/ceo-remuneration/\"\n",
      "            },\n",
      "            \"publicRationaleOutgoing\": \"The board is responsible for attracting the right CEO and setting appropriate remuneration. A substantial proportion of annual remuneration should be provided as shares that are locked in for five to ten years, regardless of resignation or retirement. The board should provide transparency on total remuneration to avoid unacceptable outcomes. The board should ensure that all benefits have a clear business rationale. Pensionable income should constitute a minor part of total remuneration.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732607,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"3\",\n",
      "        \"proposalSequence\": \"14\",\n",
      "        \"proposalText\": \"Ratify Deloitte & Touche LLP as Auditors\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"itemOnAgendaId\": 17732608,\n",
      "        \"managementRec\": \"For\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Management\",\n",
      "        \"proposalNumber\": \"4\",\n",
      "        \"proposalSequence\": \"15\",\n",
      "        \"proposalText\": \"Approve Omnibus Stock Plan\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": null\n",
      "      },\n",
      "      {\n",
      "        \"globalVotingGuidelines\": \"https://www.nbim.no/en/responsible-investment/voting/global-voting-guidelines/\",\n",
      "        \"itemOnAgendaId\": 17732748,\n",
      "        \"managementRec\": \"Against\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Shareholder\",\n",
      "        \"proposalNumber\": \"5\",\n",
      "        \"proposalSequence\": \"16\",\n",
      "        \"proposalText\": \"Report on Risks of Microsoft's ESP being Utilized for Censorship of Legitimate Speech\",\n",
      "        \"voteInstruction\": \"Against\",\n",
      "        \"voterRationale\": [\n",
      "          {\n",
      "            \"positionPaper\": {\n",
      "              \"name\": \"Position paper: Corporate sustainability reporting\",\n",
      "              \"url\": \"http://www.nbim.no/en/the-fund/responsible-investment/position-papers/corporate-sustainability-reporting/\"\n",
      "            },\n",
      "            \"publicRationaleOutgoing\": \"We will not support a shareholder proposal where the company does not appear to have significant gaps in their management or reporting of the relevant sustainability risk. We assess companies against our public expectations on environmental and social issues. We may consider direction of travel and pace of change as part of our assessments.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"globalVotingGuidelines\": \"https://www.nbim.no/en/responsible-investment/voting/global-voting-guidelines/\",\n",
      "        \"itemOnAgendaId\": 17732749,\n",
      "        \"managementRec\": \"Against\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Shareholder\",\n",
      "        \"proposalNumber\": \"6\",\n",
      "        \"proposalSequence\": \"17\",\n",
      "        \"proposalText\": \"Report on Risks of Censorship in Generative Artificial Intelligence\",\n",
      "        \"voteInstruction\": \"Against\",\n",
      "        \"voterRationale\": [\n",
      "          {\n",
      "            \"positionPaper\": {\n",
      "              \"name\": \"Position paper: Corporate sustainability reporting\",\n",
      "              \"url\": \"http://www.nbim.no/en/the-fund/responsible-investment/position-papers/corporate-sustainability-reporting/\"\n",
      "            },\n",
      "            \"publicRationaleOutgoing\": \"We will not support a shareholder proposal where the company does not appear to have significant gaps in their management or reporting of the relevant sustainability risk. We assess companies against our public expectations on environmental and social issues. We may consider direction of travel and pace of change as part of our assessments.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"globalVotingGuidelines\": \"https://www.nbim.no/en/responsible-investment/voting/global-voting-guidelines/\",\n",
      "        \"itemOnAgendaId\": 17732750,\n",
      "        \"managementRec\": \"Against\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Shareholder\",\n",
      "        \"proposalNumber\": \"7\",\n",
      "        \"proposalSequence\": \"18\",\n",
      "        \"proposalText\": \"Report on AI Data Usage Oversight\",\n",
      "        \"voteInstruction\": \"Against\",\n",
      "        \"voterRationale\": [\n",
      "          {\n",
      "            \"positionPaper\": {\n",
      "              \"name\": \"Position paper: Corporate sustainability reporting\",\n",
      "              \"url\": \"http://www.nbim.no/en/the-fund/responsible-investment/position-papers/corporate-sustainability-reporting/\"\n",
      "            },\n",
      "            \"publicRationaleOutgoing\": \"We will not support a shareholder proposal where the company does not appear to have significant gaps in their management or reporting of the relevant sustainability risk. We assess companies against our public expectations on environmental and social issues. We may consider direction of travel and pace of change as part of our assessments.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"globalVotingGuidelines\": \"https://www.nbim.no/en/responsible-investment/voting/global-voting-guidelines/\",\n",
      "        \"itemOnAgendaId\": 17732751,\n",
      "        \"managementRec\": \"Against\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Shareholder\",\n",
      "        \"proposalNumber\": \"8\",\n",
      "        \"proposalSequence\": \"19\",\n",
      "        \"proposalText\": \"Report on Risks of Operating in Countries with Significant Human Rights Concerns\",\n",
      "        \"voteInstruction\": \"For\",\n",
      "        \"voterRationale\": [\n",
      "          {\n",
      "            \"positionPaper\": {\n",
      "              \"name\": \"Position paper: Corporate sustainability reporting\",\n",
      "              \"url\": \"http://www.nbim.no/en/the-fund/responsible-investment/position-papers/corporate-sustainability-reporting/\"\n",
      "            },\n",
      "            \"publicRationaleOutgoing\": \"The board should account for material sustainability risks facing the company, and the broader environmental and social consequences of its operations and products. Sustainability disclosures should be aligned with applicable global reporting standards and frameworks to support investors in their analysis of risks and opportunities. Where a company\\u2019s disclosure does not meet our needs as a financial investor, we will consider supporting a well-founded shareholder proposal calling for reasonable disclosure. We will not support a shareholder proposal that appears to impose a strategy or prescribe detailed methods, unrealistic timeframes or targets for implementation.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"globalVotingGuidelines\": \"https://www.nbim.no/en/responsible-investment/voting/global-voting-guidelines/\",\n",
      "        \"itemOnAgendaId\": 17732752,\n",
      "        \"managementRec\": \"Against\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Shareholder\",\n",
      "        \"proposalNumber\": \"9\",\n",
      "        \"proposalSequence\": \"20\",\n",
      "        \"proposalText\": \"Human Rights Risk Assessment\",\n",
      "        \"voteInstruction\": \"Against\",\n",
      "        \"voterRationale\": [\n",
      "          {\n",
      "            \"positionPaper\": {\n",
      "              \"name\": \"Position paper: Corporate sustainability reporting\",\n",
      "              \"url\": \"http://www.nbim.no/en/the-fund/responsible-investment/position-papers/corporate-sustainability-reporting/\"\n",
      "            },\n",
      "            \"publicRationaleOutgoing\": \"We will not support a shareholder proposal where the company does not appear to have significant gaps in their management or reporting of the relevant sustainability risk. We assess companies against our public expectations on environmental and social issues. We may consider direction of travel and pace of change as part of our assessments.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"globalVotingGuidelines\": \"https://www.nbim.no/en/responsible-investment/voting/global-voting-guidelines/\",\n",
      "        \"itemOnAgendaId\": 17732753,\n",
      "        \"managementRec\": \"Against\",\n",
      "        \"meetingId\": 2017007,\n",
      "        \"proponent\": \"Shareholder\",\n",
      "        \"proposalNumber\": \"10\",\n",
      "        \"proposalSequence\": \"21\",\n",
      "        \"proposalText\": \"Report on Risks of Using Artificial Intelligence and Machine Learning Tools for Oil and Gas Development and Production\",\n",
      "        \"voteInstruction\": \"Against\",\n",
      "        \"voterRationale\": [\n",
      "          {\n",
      "            \"positionPaper\": {\n",
      "              \"name\": \"Position paper: Corporate sustainability reporting\",\n",
      "              \"url\": \"http://www.nbim.no/en/the-fund/responsible-investment/position-papers/corporate-sustainability-reporting/\"\n",
      "            },\n",
      "            \"publicRationaleOutgoing\": \"We will not support a shareholder proposal where the company does not appear to have significant gaps in their management or reporting of the relevant sustainability risk. We assess companies against our public expectations on environmental and social issues. We may consider direction of travel and pace of change as part of our assessments.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"message\": null,\n",
      "  \"status\": \"success\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the first meeting ID from Microsoft's meetings\n",
    "meeting_id = 2017007  # Most recent Microsoft meeting (2025-12-05)\n",
    "\n",
    "print(f\"TEST 2: Query meeting details (ID: {meeting_id})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Make API request to get meeting details\n",
    "response = requests.get(\n",
    "    f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    # Print structure to console\n",
    "    print(f\"\\nResponse structure:\")\n",
    "    print(json.dumps(data, indent=2))\n",
    "    \n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "293b9f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market_Value_USD</th>\n",
       "      <th>Voting</th>\n",
       "      <th>Ownership</th>\n",
       "      <th>Portfolio_Weight</th>\n",
       "      <th>Environmental</th>\n",
       "      <th>Social</th>\n",
       "      <th>Governance</th>\n",
       "      <th>Climate_change</th>\n",
       "      <th>ESG_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>sprouts farmers market inc</td>\n",
       "      <td>143113350</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>Technology</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>phison electronics corp</td>\n",
       "      <td>82621884</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>Real Estate</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>lineage inc</td>\n",
       "      <td>680636054</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.09</td>\n",
       "      <td>0.052933</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Industry         Region        Country  \\\n",
       "509   Consumer Staples  North America  United States   \n",
       "1742        Technology           Asia         Taiwan   \n",
       "1536       Real Estate  North America  United States   \n",
       "\n",
       "                            Name  Market_Value_USD  Voting  Ownership  \\\n",
       "509   sprouts farmers market inc         143113350    1.13       1.13   \n",
       "1742     phison electronics corp          82621884    2.47       2.47   \n",
       "1536                 lineage inc         680636054    5.09       5.09   \n",
       "\n",
       "      Portfolio_Weight  Environmental  Social  Governance  Climate_change  \\\n",
       "509           0.011130              1       1           1               0   \n",
       "1742          0.006426              0       0           0               0   \n",
       "1536          0.052933              1       1           1               0   \n",
       "\n",
       "      ESG_any  \n",
       "509         1  \n",
       "1742        0  \n",
       "1536        1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD P80 COMPANIES FOR PROCESSING\n",
    "DATA_PATH = \"../datasets/\"\n",
    "df_p80 =pd.read_csv(DATA_PATH +'p80_companies.csv')\n",
    "df_p80.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "883d4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Market Value descending\n",
    "df_p80 = df_p80.sort_values('Market_Value_USD', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c381189e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market_Value_USD</th>\n",
       "      <th>Voting</th>\n",
       "      <th>Ownership</th>\n",
       "      <th>Portfolio_Weight</th>\n",
       "      <th>Environmental</th>\n",
       "      <th>Social</th>\n",
       "      <th>Governance</th>\n",
       "      <th>Climate_change</th>\n",
       "      <th>ESG_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>Technology</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>apple inc</td>\n",
       "      <td>46210392003</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.593782</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>Technology</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>microsoft corp</td>\n",
       "      <td>43758827987</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.403124</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>Technology</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>nvidia corp</td>\n",
       "      <td>42973911250</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.31</td>\n",
       "      <td>3.342081</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>Technology</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>alphabet inc</td>\n",
       "      <td>29271691564</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.276459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>amazon.com inc</td>\n",
       "      <td>26979313029</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.098181</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>Technology</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>meta platforms inc</td>\n",
       "      <td>19750530468</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.535999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>Technology</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>broadcom inc</td>\n",
       "      <td>16712325272</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.299717</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>Technology</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>taiwan semiconductor manufacturing co ltd</td>\n",
       "      <td>15368120434</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.195179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Industry         Region        Country  \\\n",
       "1598              Technology  North America  United States   \n",
       "1709              Technology  North America  United States   \n",
       "1731              Technology  North America  United States   \n",
       "1593              Technology  North America  United States   \n",
       "121   Consumer Discretionary  North America  United States   \n",
       "1706              Technology  North America  United States   \n",
       "1616              Technology  North America  United States   \n",
       "1776              Technology           Asia         Taiwan   \n",
       "\n",
       "                                           Name  Market_Value_USD  Voting  \\\n",
       "1598                                  apple inc       46210392003    1.22   \n",
       "1709                             microsoft corp       43758827987    1.40   \n",
       "1731                                nvidia corp       42973911250    1.31   \n",
       "1593                               alphabet inc       29271691564    0.88   \n",
       "121                              amazon.com inc       26979313029    1.17   \n",
       "1706                         meta platforms inc       19750530468    0.60   \n",
       "1616                               broadcom inc       16712325272    1.54   \n",
       "1776  taiwan semiconductor manufacturing co ltd       15368120434    1.80   \n",
       "\n",
       "      Ownership  Portfolio_Weight  Environmental  Social  Governance  \\\n",
       "1598       1.22          3.593782              0       1           1   \n",
       "1709       1.40          3.403124              0       1           1   \n",
       "1731       1.31          3.342081              1       0           1   \n",
       "1593       1.26          2.276459              0       1           1   \n",
       "121        1.17          2.098181              1       1           1   \n",
       "1706       1.34          1.535999              1       1           1   \n",
       "1616       1.54          1.299717              0       0           1   \n",
       "1776       1.80          1.195179              0       0           0   \n",
       "\n",
       "      Climate_change  ESG_any  \n",
       "1598               0        1  \n",
       "1709               0        1  \n",
       "1731               1        1  \n",
       "1593               0        1  \n",
       "121                1        1  \n",
       "1706               1        1  \n",
       "1616               0        1  \n",
       "1776               0        0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p80.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfc0dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "939d2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for a test\n",
    "df_p80 = df_p80.head(50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21c81fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies to process: 50\n",
      "Progress: 50/50 (100.0%) - Est. 0.0 min remaining\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Total companies processed: 50\n",
      "Total errors: 17\n",
      "Total disagreements found: 315\n",
      "\n",
      "Companies with disagreements: 25\n",
      "Companies with zero disagreements: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total companies to process: {len(df_p80)}\")\n",
    "\n",
    "# CHECKPOINT: Check if we have partial progress\n",
    "checkpoint_file = 'checkpoint_progress.csv'\n",
    "disagreements_file = 'checkpoint_disagreements.csv'\n",
    "stats_file = 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies already done\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "# Track progress\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100  # Save every 100 companies\n",
    "\n",
    "for idx, row in df_p80.iterrows():\n",
    "    company_name = row['Name']\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    # Progress update every 50 companies\n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_p80) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_p80)} ({processed/len(df_p80)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Get company info and meetings\n",
    "        response = requests.get(\n",
    "            f\"{BASE_URL}/v1/query/company/{company_name}\",\n",
    "            headers=headers,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        # Check if companies array exists\n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        # Filter meetings from 2020 onwards\n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        # Stats for this company\n",
    "        total_disagreements = 0\n",
    "        \n",
    "        # Step 2: Process each meeting\n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            # Get meeting details\n",
    "            time.sleep(0.1)  # Rate limiting\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            # Identify disagreements\n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                # DISAGREEMENT: when different\n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    # Extract rationale info\n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    # Store disagreement\n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        # Store company-level stats\n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        # CHECKPOINT: Save progress every 100 companies\n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "# Final save\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4aa27cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE DISAGREEMENTS:\n",
      "  company_name ticker        country         meeting_date  meeting_id  \\\n",
      "0    apple inc   AAPL  United States  2024-02-28 00:00:00     1815577   \n",
      "1    apple inc   AAPL  United States  2024-02-28 00:00:00     1815577   \n",
      "2    apple inc   AAPL  United States  2023-03-10 00:00:00     1709502   \n",
      "3    apple inc   AAPL  United States  2023-03-10 00:00:00     1709502   \n",
      "4    apple inc   AAPL  United States  2022-03-04 00:00:00     1601071   \n",
      "5    apple inc   AAPL  United States  2022-03-04 00:00:00     1601071   \n",
      "6    apple inc   AAPL  United States  2022-03-04 00:00:00     1601071   \n",
      "7    apple inc   AAPL  United States  2022-03-04 00:00:00     1601071   \n",
      "8    apple inc   AAPL  United States  2022-03-04 00:00:00     1601071   \n",
      "9    apple inc   AAPL  United States  2020-02-26 00:00:00     1388634   \n",
      "\n",
      "  meeting_type proposal_number  \\\n",
      "0       Annual               6   \n",
      "1       Annual               7   \n",
      "2       Annual               3   \n",
      "3       Annual               8   \n",
      "4       Annual               3   \n",
      "5       Annual               6   \n",
      "6       Annual               7   \n",
      "7       Annual               9   \n",
      "8       Annual              10   \n",
      "9       Annual               4   \n",
      "\n",
      "                                       proposal_text    proponent  \\\n",
      "0             Report on Median Gender/Racial Pay Gap  Shareholder   \n",
      "1           Report on Use of Artificial Intelligence  Shareholder   \n",
      "2  Advisory Vote to Ratify Named Executive Office...   Management   \n",
      "3             Report on Median Gender/Racial Pay Gap  Shareholder   \n",
      "4  Advisory Vote to Ratify Named Executive Office...   Management   \n",
      "5           Approve Revision of Transparency Reports  Shareholder   \n",
      "6                             Report on Forced Labor  Shareholder   \n",
      "7                       Report on Civil Rights Audit  Shareholder   \n",
      "8                      Report on Concealment Clauses  Shareholder   \n",
      "9                            Proxy Access Amendments  Shareholder   \n",
      "\n",
      "  management_rec nbim_vote                                     position_paper  \\\n",
      "0        Against       For  Position paper: Corporate sustainability repor...   \n",
      "1        Against       For  Position paper: Corporate sustainability repor...   \n",
      "2            For   Against                   Position paper: CEO remuneration   \n",
      "3        Against       For  Position paper: Corporate sustainability repor...   \n",
      "4            For   Against                   Position paper: CEO remuneration   \n",
      "5        Against       For  Position paper: Corporate sustainability repor...   \n",
      "6        Against       For  Position paper: Corporate sustainability repor...   \n",
      "7        Against       For  Position paper: Corporate sustainability repor...   \n",
      "8        Against       For  Position paper: Corporate sustainability repor...   \n",
      "9        Against       For                                                      \n",
      "\n",
      "                                      rationale_text  \n",
      "0  The board should account for material sustaina...  \n",
      "1  The board should account for material sustaina...  \n",
      "2  The board is responsible for attracting the ri...  \n",
      "3  The board should account for material sustaina...  \n",
      "4  The board is responsible for attracting the ri...  \n",
      "5  The board should account for material sustaina...  \n",
      "6  The board should account for material sustaina...  \n",
      "7  The board should account for material sustaina...  \n",
      "8  The board should account for material sustaina...  \n",
      "9                                                     \n",
      "\n",
      "============================================================\n",
      "ERRORS:\n",
      "                                      company             error\n",
      "0                              amazon.com inc  No data returned\n",
      "1                          meta platforms inc  No data returned\n",
      "2   taiwan semiconductor manufacturing co ltd  No data returned\n",
      "3                                   tesla inc  No data returned\n",
      "4                              eli lilly & co  No data returned\n",
      "5                            novo nordisk a/s        Status 404\n",
      "6                        tencent holdings ltd  No data returned\n",
      "7                     procter & gamble co/the        Status 404\n",
      "8                          home depot inc/the        Status 404\n",
      "9                                 netflix inc  No data returned\n",
      "10                  alibaba group holding ltd  No data returned\n",
      "11                 samsung electronics co ltd  No data returned\n",
      "12                   digital realty trust inc  No data returned\n",
      "13                             salesforce inc  No data returned\n",
      "14                         nextera energy inc  No data returned\n",
      "15                             merck & co inc  No data returned\n",
      "16                           coca-cola co/the        Status 404\n",
      "\n",
      "============================================================\n",
      "COMPANY STATS:\n",
      "             company_name ticker  total_meetings_2020_plus  \\\n",
      "0               apple inc   AAPL                         6   \n",
      "1          microsoft corp   MSFT                         6   \n",
      "2             nvidia corp   NVDA                         6   \n",
      "3            alphabet inc  GOOGL                         6   \n",
      "4            broadcom inc   AVGO                         6   \n",
      "5  berkshire hathaway inc  BRK.B                         6   \n",
      "6     jpmorgan chase & co    JPM                         6   \n",
      "7                  sap se    SAP                         6   \n",
      "8         asml holding nv   ASML                        12   \n",
      "9        exxon mobil corp    XOM                         6   \n",
      "\n",
      "   total_disagreements  \n",
      "0                   10  \n",
      "1                   17  \n",
      "2                    1  \n",
      "3                   39  \n",
      "4                    4  \n",
      "5                   56  \n",
      "6                   14  \n",
      "7                    0  \n",
      "8                    0  \n",
      "9                   43  \n"
     ]
    }
   ],
   "source": [
    "# View sample of disagreements\n",
    "print(\"SAMPLE DISAGREEMENTS:\")\n",
    "print(df_disagreements.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# View which companies had errors\n",
    "print(\"ERRORS:\")\n",
    "print(df_errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# View statistics per company\n",
    "print(\"COMPANY STATS:\")\n",
    "print(df_stats.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a51c326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies to process: 50\n",
      "Progress: 50/50 (100.0%) - Est. 0.0 min remaining\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Total companies processed: 50\n",
      "Total errors: 7\n",
      "Total disagreements found: 172\n",
      "\n",
      "Companies with disagreements: 32\n",
      "Companies with zero disagreements: 11\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total companies to process: {len(df_p80)}\")\n",
    "\n",
    "# CHECKPOINT: Check if we have partial progress\n",
    "checkpoint_file = 'checkpoint_progress.csv'\n",
    "disagreements_file = 'checkpoint_disagreements.csv'\n",
    "stats_file = 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies already done\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "# Track progress\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100\n",
    "\n",
    "for idx, row in df_p80.iterrows():\n",
    "    company_name = row['Name']\n",
    "    ticker = row.get('Ticker', '')\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    # Progress update every 50 companies\n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_p80) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_p80)} ({processed/len(df_p80)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Try by company name\n",
    "        response = requests.get(\n",
    "            f\"{BASE_URL}/v1/query/company/{company_name}\",\n",
    "            headers=headers,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        # Check if first attempt failed\n",
    "        if response.status_code != 200 or 'companies' not in response.json() or len(response.json()['companies']) == 0:\n",
    "            # FALLBACK: Try by ticker\n",
    "            if ticker:\n",
    "                print(f\"  → Retrying '{company_name}' with ticker '{ticker}'\")\n",
    "                time.sleep(0.1)\n",
    "                response = requests.get(\n",
    "                    f\"{BASE_URL}/v1/query/ticker/{ticker}\",\n",
    "                    headers=headers,\n",
    "                    timeout=10\n",
    "                )\n",
    "        \n",
    "        # If still failed, log error and continue\n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        # Check if companies array exists\n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        # Filter meetings from 2020 onwards\n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        # Stats for this company\n",
    "        total_disagreements = 0\n",
    "        \n",
    "        # Step 2: Process each meeting\n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            # Get meeting details\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            # Identify disagreements\n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                # DISAGREEMENT: when different\n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    # Extract rationale info\n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    # Store disagreement\n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        # Store company-level stats\n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        # CHECKPOINT: Save progress every 100 companies\n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'ticker': ticker, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "# Final save\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9d6dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMAINING ERRORS:\n",
      "                          company ticker             error\n",
      "0          agnico eagle mines ltd         No data returned\n",
      "1  air products and chemicals inc         No data returned\n",
      "2                 alamos gold inc         No data returned\n",
      "3                   bhp group ltd         No data returned\n",
      "4      cf industries holdings inc         No data returned\n",
      "5    ganfeng lithium group co ltd         No data returned\n",
      "6          grupo mexico sab de cv         No data returned\n",
      "\n",
      "============================================================\n",
      "TOP 10 COMPANIES BY DISAGREEMENTS:\n",
      "             company_name  total_disagreements\n",
      "40          icl group ltd                   32\n",
      "24             ecolab inc                   14\n",
      "25       empresas cmpc sa                   14\n",
      "22                dow inc                   10\n",
      "23    eastman chemical co                   10\n",
      "19   cleveland-cliffs inc                    9\n",
      "36            givaudan sa                    8\n",
      "3          albemarle corp                    7\n",
      "26  ems-chemie holding ag                    7\n",
      "35              gerdau sa                    7\n"
     ]
    }
   ],
   "source": [
    "# Check which companies had errors\n",
    "print(\"REMAINING ERRORS:\")\n",
    "print(df_errors[['company', 'ticker', 'error']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check companies with most disagreements\n",
    "print(\"TOP 10 COMPANIES BY DISAGREEMENTS:\")\n",
    "print(df_stats.nlargest(10, 'total_disagreements')[['company_name', 'total_disagreements']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1b3fa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>country</th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>meeting_type</th>\n",
       "      <th>proposal_number</th>\n",
       "      <th>proposal_text</th>\n",
       "      <th>proponent</th>\n",
       "      <th>management_rec</th>\n",
       "      <th>nbim_vote</th>\n",
       "      <th>position_paper</th>\n",
       "      <th>rationale_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acerinox sa</td>\n",
       "      <td>ACX</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2020-10-21 00:00:00</td>\n",
       "      <td>1471725</td>\n",
       "      <td>Annual</td>\n",
       "      <td>9</td>\n",
       "      <td>Authorize Issuance of Convertible Bonds, Deben...</td>\n",
       "      <td>Management</td>\n",
       "      <td>For</td>\n",
       "      <td>Against</td>\n",
       "      <td>Position paper: Shareholder rights in equity i...</td>\n",
       "      <td>Existing shareholders should have the right to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air liquide sa</td>\n",
       "      <td>AI</td>\n",
       "      <td>France</td>\n",
       "      <td>2021-05-04 00:00:00</td>\n",
       "      <td>1504230</td>\n",
       "      <td>Annual/Special</td>\n",
       "      <td>8</td>\n",
       "      <td>Elect Bertrand Dumazy as Director</td>\n",
       "      <td>Management</td>\n",
       "      <td>For</td>\n",
       "      <td>Against</td>\n",
       "      <td>Position paper: Time commitment of board members</td>\n",
       "      <td>Board members should devote sufficient time to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albemarle corp</td>\n",
       "      <td>ALB</td>\n",
       "      <td>United States</td>\n",
       "      <td>2025-05-06 00:00:00</td>\n",
       "      <td>1946039</td>\n",
       "      <td>Annual</td>\n",
       "      <td>1c</td>\n",
       "      <td>Elect Director J. Kent Masters, Jr.</td>\n",
       "      <td>Management</td>\n",
       "      <td>For</td>\n",
       "      <td>Against</td>\n",
       "      <td>Position paper: Separation of chairperson and CEO</td>\n",
       "      <td>The board should exercise objective judgement ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company_name ticker        country         meeting_date  meeting_id  \\\n",
       "0     acerinox sa    ACX          Spain  2020-10-21 00:00:00     1471725   \n",
       "1  air liquide sa     AI         France  2021-05-04 00:00:00     1504230   \n",
       "2  albemarle corp    ALB  United States  2025-05-06 00:00:00     1946039   \n",
       "\n",
       "     meeting_type proposal_number  \\\n",
       "0          Annual               9   \n",
       "1  Annual/Special               8   \n",
       "2          Annual              1c   \n",
       "\n",
       "                                       proposal_text   proponent  \\\n",
       "0  Authorize Issuance of Convertible Bonds, Deben...  Management   \n",
       "1                  Elect Bertrand Dumazy as Director  Management   \n",
       "2                Elect Director J. Kent Masters, Jr.  Management   \n",
       "\n",
       "  management_rec nbim_vote                                     position_paper  \\\n",
       "0            For   Against  Position paper: Shareholder rights in equity i...   \n",
       "1            For   Against   Position paper: Time commitment of board members   \n",
       "2            For   Against  Position paper: Separation of chairperson and CEO   \n",
       "\n",
       "                                      rationale_text  \n",
       "0  Existing shareholders should have the right to...  \n",
       "1  Board members should devote sufficient time to...  \n",
       "2  The board should exercise objective judgement ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagreements.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60ad942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>country</th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>meeting_type</th>\n",
       "      <th>proposal_number</th>\n",
       "      <th>proposal_text</th>\n",
       "      <th>proponent</th>\n",
       "      <th>management_rec</th>\n",
       "      <th>nbim_vote</th>\n",
       "      <th>position_paper</th>\n",
       "      <th>rationale_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>gerdau sa</td>\n",
       "      <td>GGBR4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2025-04-10 00:00:00</td>\n",
       "      <td>1939048</td>\n",
       "      <td>Annual</td>\n",
       "      <td>1</td>\n",
       "      <td>As a Preferred Shareholder, Would You like to ...</td>\n",
       "      <td>Management</td>\n",
       "      <td>None</td>\n",
       "      <td>Abstain</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>gerdau sa</td>\n",
       "      <td>GGBR4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2025-04-10 00:00:00</td>\n",
       "      <td>1939048</td>\n",
       "      <td>Annual</td>\n",
       "      <td>2</td>\n",
       "      <td>Elect Denisio Augusto Liberato Delfino as Fisc...</td>\n",
       "      <td>Shareholder</td>\n",
       "      <td>None</td>\n",
       "      <td>For</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>gerdau sa</td>\n",
       "      <td>GGBR4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2025-04-10 00:00:00</td>\n",
       "      <td>1939048</td>\n",
       "      <td>Annual</td>\n",
       "      <td>3</td>\n",
       "      <td>In Case Neither Class of Shares Reaches the Mi...</td>\n",
       "      <td>Management</td>\n",
       "      <td>None</td>\n",
       "      <td>For</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>gerdau sa</td>\n",
       "      <td>GGBR4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2024-04-16 00:00:00</td>\n",
       "      <td>1835336</td>\n",
       "      <td>Annual</td>\n",
       "      <td>1</td>\n",
       "      <td>As a Preferred Shareholder, Would You like to ...</td>\n",
       "      <td>Management</td>\n",
       "      <td>None</td>\n",
       "      <td>For</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>gerdau sa</td>\n",
       "      <td>GGBR4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2024-04-16 00:00:00</td>\n",
       "      <td>1835336</td>\n",
       "      <td>Annual</td>\n",
       "      <td>2</td>\n",
       "      <td>Elect Claudio Antonio Goncalves as Director Ap...</td>\n",
       "      <td>Shareholder</td>\n",
       "      <td>None</td>\n",
       "      <td>For</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>gerdau sa</td>\n",
       "      <td>GGBR4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2024-04-16 00:00:00</td>\n",
       "      <td>1835336</td>\n",
       "      <td>Annual</td>\n",
       "      <td>3</td>\n",
       "      <td>In Case Neither Class of Shares Reaches the Mi...</td>\n",
       "      <td>Management</td>\n",
       "      <td>None</td>\n",
       "      <td>For</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>gerdau sa</td>\n",
       "      <td>GGBR4</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2024-04-16 00:00:00</td>\n",
       "      <td>1835336</td>\n",
       "      <td>Annual</td>\n",
       "      <td>4</td>\n",
       "      <td>Elect Denisio Augusto Liberato Delfino as Fisc...</td>\n",
       "      <td>Shareholder</td>\n",
       "      <td>None</td>\n",
       "      <td>For</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    company_name ticker country         meeting_date  meeting_id meeting_type  \\\n",
       "112    gerdau sa  GGBR4  Brazil  2025-04-10 00:00:00     1939048       Annual   \n",
       "113    gerdau sa  GGBR4  Brazil  2025-04-10 00:00:00     1939048       Annual   \n",
       "114    gerdau sa  GGBR4  Brazil  2025-04-10 00:00:00     1939048       Annual   \n",
       "115    gerdau sa  GGBR4  Brazil  2024-04-16 00:00:00     1835336       Annual   \n",
       "116    gerdau sa  GGBR4  Brazil  2024-04-16 00:00:00     1835336       Annual   \n",
       "117    gerdau sa  GGBR4  Brazil  2024-04-16 00:00:00     1835336       Annual   \n",
       "118    gerdau sa  GGBR4  Brazil  2024-04-16 00:00:00     1835336       Annual   \n",
       "\n",
       "    proposal_number                                      proposal_text  \\\n",
       "112               1  As a Preferred Shareholder, Would You like to ...   \n",
       "113               2  Elect Denisio Augusto Liberato Delfino as Fisc...   \n",
       "114               3  In Case Neither Class of Shares Reaches the Mi...   \n",
       "115               1  As a Preferred Shareholder, Would You like to ...   \n",
       "116               2  Elect Claudio Antonio Goncalves as Director Ap...   \n",
       "117               3  In Case Neither Class of Shares Reaches the Mi...   \n",
       "118               4  Elect Denisio Augusto Liberato Delfino as Fisc...   \n",
       "\n",
       "       proponent management_rec nbim_vote position_paper rationale_text  \n",
       "112   Management           None   Abstain                                \n",
       "113  Shareholder           None       For                                \n",
       "114   Management           None       For                                \n",
       "115   Management           None       For                                \n",
       "116  Shareholder           None       For                                \n",
       "117   Management           None       For                                \n",
       "118  Shareholder           None       For                                "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagreements[df_disagreements['company_name'].str.contains('gerdau')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "793df436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33ab5c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market_Value_USD</th>\n",
       "      <th>Voting</th>\n",
       "      <th>Ownership</th>\n",
       "      <th>Portfolio_Weight</th>\n",
       "      <th>Environmental</th>\n",
       "      <th>Social</th>\n",
       "      <th>Governance</th>\n",
       "      <th>Climate_change</th>\n",
       "      <th>ESG_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>alamos gold inc</td>\n",
       "      <td>100771261</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Industry         Region Country             Name  Market_Value_USD  \\\n",
       "5  Basic Materials  North America  Canada  alamos gold inc         100771261   \n",
       "\n",
       "   Voting  Ownership  Portfolio_Weight  Environmental  Social  Governance  \\\n",
       "5     1.3        1.3          0.007837              0       0           0   \n",
       "\n",
       "   Climate_change  ESG_any  \n",
       "5               0        0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p80[df_p80['Name'].str.contains('alamos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c888a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 13)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same dataframe will be used\n",
    "df_p80.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f51af064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checkpoints cleared\n"
     ]
    }
   ],
   "source": [
    "#Erasing previous checkpoints for trying a new approach to correct mistakes\n",
    "\n",
    "# Delete old checkpoints\n",
    "files_to_delete = ['checkpoint_progress.csv', 'checkpoint_disagreements.csv', 'checkpoint_stats.csv']\n",
    "\n",
    "for file in files_to_delete:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"✓ Deleted {file}\")\n",
    "\n",
    "print(\"\\nCheckpoints cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2a99f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies to process: 50\n",
      "Progress: 50/50 (100.0%) - Est. 0.0 min remaining\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Total companies processed: 50\n",
      "Total errors: 7\n",
      "Total disagreements found: 172\n",
      "\n",
      "Companies with disagreements: 32\n",
      "Companies with zero disagreements: 11\n"
     ]
    }
   ],
   "source": [
    "def clean_company_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    # Remove punctuation and parentheses\n",
    "    name = re.sub(r'[.,()&/]', '', name)\n",
    "    # Replace multiple spaces with single space\n",
    "    name = ' '.join(name.split())\n",
    "    return name.strip()\n",
    "\n",
    "print(f\"Total companies to process: {len(df_p80)}\")\n",
    "\n",
    "# CHECKPOINT: Check if we have partial progress\n",
    "checkpoint_file = 'checkpoint_progress.csv'\n",
    "disagreements_file = 'checkpoint_disagreements.csv'\n",
    "stats_file = 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies already done\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "# Track progress\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100\n",
    "\n",
    "for idx, row in df_p80.iterrows():\n",
    "    company_name = row['Name']\n",
    "    ticker = row.get('Ticker', '')\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    # Progress update every 50 companies\n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_p80) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_p80)} ({processed/len(df_p80)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        # STRATEGY: Try ticker first (if available), then name\n",
    "        response = None\n",
    "        \n",
    "        # Try 1: Search by ticker (more reliable)\n",
    "        if ticker and ticker.strip():\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/ticker/{ticker}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200 and 'companies' in response.json() and len(response.json()['companies']) > 0:\n",
    "                # Ticker worked\n",
    "                pass\n",
    "            else:\n",
    "                # Ticker failed, try name\n",
    "                response = None\n",
    "        \n",
    "        # Try 2: Search by company name (if ticker failed or not available)\n",
    "        if response is None:\n",
    "            clean_name = clean_company_name(company_name)\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/company/{clean_name}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "        \n",
    "        # If both failed, log error and continue\n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        # Check if companies array exists\n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        # Filter meetings from 2020 onwards\n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        # Stats for this company\n",
    "        total_disagreements = 0\n",
    "        \n",
    "        # Step 2: Process each meeting\n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            # Get meeting details\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            # Identify disagreements\n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                # SKIP if management_rec is None or empty\n",
    "                if mgmt_rec is None or mgmt_rec == '' or pd.isna(mgmt_rec):\n",
    "                    continue\n",
    "                \n",
    "                # SKIP if nbim_vote is None or empty\n",
    "                if nbim_vote is None or nbim_vote == '' or pd.isna(nbim_vote):\n",
    "                    continue\n",
    "                \n",
    "                # DISAGREEMENT: when different\n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    # Extract rationale info\n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    # Store disagreement\n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        # Store company-level stats\n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        # CHECKPOINT: Save progress every 100 companies\n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'ticker': ticker, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "# Final save\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79c0177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMAINING ERRORS:\n",
      "                          company ticker             error\n",
      "0          agnico eagle mines ltd         No data returned\n",
      "1  air products and chemicals inc         No data returned\n",
      "2                 alamos gold inc         No data returned\n",
      "3                   bhp group ltd         No data returned\n",
      "4      cf industries holdings inc         No data returned\n",
      "5    ganfeng lithium group co ltd         No data returned\n",
      "6          grupo mexico sab de cv         No data returned\n",
      "\n",
      "============================================================\n",
      "TOP 10 COMPANIES BY DISAGREEMENTS:\n",
      "             company_name  total_disagreements\n",
      "40          icl group ltd                   32\n",
      "24             ecolab inc                   14\n",
      "25       empresas cmpc sa                   14\n",
      "22                dow inc                   10\n",
      "23    eastman chemical co                   10\n",
      "19   cleveland-cliffs inc                    9\n",
      "36            givaudan sa                    8\n",
      "3          albemarle corp                    7\n",
      "26  ems-chemie holding ag                    7\n",
      "35              gerdau sa                    7\n"
     ]
    }
   ],
   "source": [
    "# Check which companies had errors\n",
    "print(\"REMAINING ERRORS:\")\n",
    "print(df_errors[['company', 'ticker', 'error']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check companies with most disagreements\n",
    "print(\"TOP 10 COMPANIES BY DISAGREEMENTS:\")\n",
    "print(df_stats.nlargest(10, 'total_disagreements')[['company_name', 'total_disagreements']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff0dd2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ICL disagreements: 32\n",
      "\n",
      "Sample of ICL disagreements:\n",
      "    proposal_number management_rec nbim_vote\n",
      "137               A           None   Against\n",
      "138              B1           None   Against\n",
      "139              B2           None   Against\n",
      "140              B3           None   Against\n",
      "141               A           None   Against\n",
      "142              B1           None   Against\n",
      "143              B2           None   Against\n",
      "144              B3           None   Against\n",
      "145               A           None   Against\n",
      "146              B1           None   Against\n",
      "\n",
      "============================================================\n",
      "Checking for None values:\n",
      "Proposals with None in management_rec: 0\n",
      "Proposals with None as string: 32\n"
     ]
    }
   ],
   "source": [
    "# Check ICL disagreements - verify None filtering worked\n",
    "icl_disagreements = df_disagreements[df_disagreements['company_name'].str.contains('icl', case=False)]\n",
    "\n",
    "print(f\"Total ICL disagreements: {len(icl_disagreements)}\")\n",
    "print(\"\\nSample of ICL disagreements:\")\n",
    "print(icl_disagreements[['proposal_number', 'management_rec', 'nbim_vote']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Checking for None values:\")\n",
    "print(f\"Proposals with None in management_rec: {icl_disagreements['management_rec'].isna().sum()}\")\n",
    "print(f\"Proposals with None as string: {(icl_disagreements['management_rec'] == 'None').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "acfc34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ['checkpoint_progress.csv', 'checkpoint_disagreements.csv', 'checkpoint_stats.csv']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94d0e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies to process: 50\n",
      "Progress: 50/50 (100.0%) - Est. 0.0 min remaining\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Total companies processed: 50\n",
      "Total errors: 7\n",
      "Total disagreements found: 129\n",
      "\n",
      "Companies with disagreements: 28\n",
      "Companies with zero disagreements: 15\n"
     ]
    }
   ],
   "source": [
    "def clean_company_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    # Remove punctuation and parentheses\n",
    "    name = re.sub(r'[.,()&/]', '', name)\n",
    "    # Replace multiple spaces with single space\n",
    "    name = ' '.join(name.split())\n",
    "    return name.strip()\n",
    "\n",
    "print(f\"Total companies to process: {len(df_p80)}\")\n",
    "\n",
    "# CHECKPOINT: Check if we have partial progress\n",
    "checkpoint_file = 'checkpoint_progress.csv'\n",
    "disagreements_file = 'checkpoint_disagreements.csv'\n",
    "stats_file = 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies already done\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "# Track progress\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100\n",
    "\n",
    "for idx, row in df_p80.iterrows():\n",
    "    company_name = row['Name']\n",
    "    ticker = row.get('Ticker', '')\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    # Progress update every 50 companies\n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_p80) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_p80)} ({processed/len(df_p80)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        # STRATEGY: Try ticker first (if available), then name\n",
    "        response = None\n",
    "        \n",
    "        # Try 1: Search by ticker (more reliable)\n",
    "        if ticker and ticker.strip():\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/ticker/{ticker}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200 and 'companies' in response.json() and len(response.json()['companies']) > 0:\n",
    "                # Ticker worked\n",
    "                pass\n",
    "            else:\n",
    "                # Ticker failed, try name\n",
    "                response = None\n",
    "        \n",
    "        # Try 2: Search by company name (if ticker failed or not available)\n",
    "        if response is None:\n",
    "            clean_name = clean_company_name(company_name)\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/company/{clean_name}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "        \n",
    "        # If both failed, log error and continue\n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        # Check if companies array exists\n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        # Filter meetings from 2020 onwards\n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        # Stats for this company\n",
    "        total_disagreements = 0\n",
    "        \n",
    "        # Step 2: Process each meeting\n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            # Get meeting details\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            # Identify disagreements\n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                # SKIP if management_rec is None, empty, or string \"None\"\n",
    "                if mgmt_rec is None or mgmt_rec == '' or pd.isna(mgmt_rec) or str(mgmt_rec) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                # SKIP if nbim_vote is None, empty, or string \"None\"\n",
    "                if nbim_vote is None or nbim_vote == '' or pd.isna(nbim_vote) or str(nbim_vote) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                # DISAGREEMENT: when different\n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    # Extract rationale info\n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    # Store disagreement\n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        # Store company-level stats\n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        # CHECKPOINT: Save progress every 100 companies\n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'ticker': ticker, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "# Final save\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a9e0146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMAINING ERRORS:\n",
      "                          company ticker             error\n",
      "0          agnico eagle mines ltd         No data returned\n",
      "1  air products and chemicals inc         No data returned\n",
      "2                 alamos gold inc         No data returned\n",
      "3                   bhp group ltd         No data returned\n",
      "4      cf industries holdings inc         No data returned\n",
      "5    ganfeng lithium group co ltd         No data returned\n",
      "6          grupo mexico sab de cv         No data returned\n",
      "\n",
      "============================================================\n",
      "TOP 10 COMPANIES BY DISAGREEMENTS:\n",
      "             company_name  total_disagreements\n",
      "24             ecolab inc                   14\n",
      "25       empresas cmpc sa                   14\n",
      "22                dow inc                   10\n",
      "23    eastman chemical co                   10\n",
      "19   cleveland-cliffs inc                    9\n",
      "36            givaudan sa                    8\n",
      "3          albemarle corp                    7\n",
      "26  ems-chemie holding ag                    7\n",
      "38              holmen ab                    7\n",
      "18          celanese corp                    5\n"
     ]
    }
   ],
   "source": [
    "# Check which companies had errors\n",
    "print(\"REMAINING ERRORS:\")\n",
    "print(df_errors[['company', 'ticker', 'error']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check companies with most disagreements\n",
    "print(\"TOP 10 COMPANIES BY DISAGREEMENTS:\")\n",
    "print(df_stats.nlargest(10, 'total_disagreements')[['company_name', 'total_disagreements']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0bf90ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1925, 13)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restablishing the dataset to its original size and content\n",
    "# LOAD P80 COMPANIES FOR PROCESSING\n",
    "DATA_PATH = \"../datasets/\"\n",
    "df_p80 =pd.read_csv(DATA_PATH +'p80_companies.csv')\n",
    "df_p80.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbe3a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erasing checkpoints for being able to analyze from scratch\n",
    "for file in ['checkpoint_progress.csv', 'checkpoint_disagreements.csv', 'checkpoint_stats.csv']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"✓ Deleted {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fce28f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies to process: 1925\n",
      "Progress: 50/1925 (2.6%) - Est. 150.6 min remaining\n",
      "Progress: 100/1925 (5.2%) - Est. 117.1 min remaining\n",
      "Progress: 150/1925 (7.8%) - Est. 103.7 min remaining\n",
      "Progress: 200/1925 (10.4%) - Est. 91.7 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 200 companies\n",
      "Progress: 250/1925 (13.0%) - Est. 88.9 min remaining\n",
      "Progress: 300/1925 (15.6%) - Est. 86.8 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 300 companies\n",
      "Progress: 350/1925 (18.2%) - Est. 84.4 min remaining\n",
      "Progress: 400/1925 (20.8%) - Est. 81.5 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 400 companies\n",
      "Progress: 450/1925 (23.4%) - Est. 76.5 min remaining\n",
      "Progress: 500/1925 (26.0%) - Est. 72.2 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 500 companies\n",
      "Progress: 550/1925 (28.6%) - Est. 68.5 min remaining\n",
      "Progress: 600/1925 (31.2%) - Est. 68.6 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 600 companies\n",
      "Progress: 650/1925 (33.8%) - Est. 67.4 min remaining\n",
      "Progress: 700/1925 (36.4%) - Est. 65.1 min remaining\n",
      "Progress: 750/1925 (39.0%) - Est. 59.3 min remaining\n",
      "Progress: 800/1925 (41.6%) - Est. 54.2 min remaining\n",
      "Progress: 850/1925 (44.2%) - Est. 49.5 min remaining\n",
      "Progress: 900/1925 (46.8%) - Est. 45.2 min remaining\n",
      "Progress: 950/1925 (49.4%) - Est. 41.3 min remaining\n",
      "Progress: 1000/1925 (51.9%) - Est. 37.8 min remaining\n",
      "Progress: 1050/1925 (54.5%) - Est. 34.6 min remaining\n",
      "Progress: 1100/1925 (57.1%) - Est. 31.6 min remaining\n",
      "Progress: 1150/1925 (59.7%) - Est. 28.8 min remaining\n",
      "Progress: 1200/1925 (62.3%) - Est. 26.1 min remaining\n",
      "Progress: 1250/1925 (64.9%) - Est. 23.7 min remaining\n",
      "Progress: 1300/1925 (67.5%) - Est. 21.3 min remaining\n",
      "Progress: 1350/1925 (70.1%) - Est. 19.1 min remaining\n",
      "Progress: 1400/1925 (72.7%) - Est. 17.1 min remaining\n",
      "Progress: 1450/1925 (75.3%) - Est. 15.1 min remaining\n",
      "Progress: 1500/1925 (77.9%) - Est. 13.2 min remaining\n",
      "Progress: 1550/1925 (80.5%) - Est. 11.3 min remaining\n",
      "Progress: 1600/1925 (83.1%) - Est. 9.6 min remaining\n",
      "Progress: 1650/1925 (85.7%) - Est. 8.0 min remaining\n",
      "Progress: 1700/1925 (88.3%) - Est. 6.4 min remaining\n",
      "Progress: 1750/1925 (90.9%) - Est. 4.9 min remaining\n",
      "Progress: 1800/1925 (93.5%) - Est. 3.4 min remaining\n",
      "Progress: 1850/1925 (96.1%) - Est. 2.0 min remaining\n",
      "Progress: 1900/1925 (98.7%) - Est. 0.7 min remaining\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Total companies processed: 1925\n",
      "Total errors: 1554\n",
      "Total disagreements found: 1805\n",
      "\n",
      "Companies with disagreements: 243\n",
      "Companies with zero disagreements: 128\n"
     ]
    }
   ],
   "source": [
    "def clean_company_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = re.sub(r'[.,()&/]', '', name)\n",
    "    name = ' '.join(name.split())\n",
    "    return name.strip()\n",
    "\n",
    "print(f\"Total companies to process: {len(df_p80)}\")\n",
    "\n",
    "checkpoint_file = 'checkpoint_progress.csv'\n",
    "disagreements_file = 'checkpoint_disagreements.csv'\n",
    "stats_file = 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies already done\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100\n",
    "\n",
    "for idx, row in df_p80.iterrows():\n",
    "    company_name = row['Name']\n",
    "    ticker = row.get('Ticker', '')\n",
    "    \n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_p80) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_p80)} ({processed/len(df_p80)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        response = None\n",
    "        \n",
    "        if ticker and ticker.strip():\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/ticker/{ticker}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200 and 'companies' in response.json() and len(response.json()['companies']) > 0:\n",
    "                pass\n",
    "            else:\n",
    "                response = None\n",
    "        \n",
    "        if response is None:\n",
    "            clean_name = clean_company_name(company_name)\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/company/{clean_name}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        total_disagreements = 0\n",
    "        \n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                if mgmt_rec is None or mgmt_rec == '' or pd.isna(mgmt_rec) or str(mgmt_rec) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                if nbim_vote is None or nbim_vote == '' or pd.isna(nbim_vote) or str(nbim_vote) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'ticker': ticker, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a438df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMAINING ERRORS:\n",
      "                             company ticker             error\n",
      "0             agnico eagle mines ltd         No data returned\n",
      "1     air products and chemicals inc         No data returned\n",
      "2                    alamos gold inc         No data returned\n",
      "3                      bhp group ltd         No data returned\n",
      "4         cf industries holdings inc         No data returned\n",
      "...                              ...    ...               ...\n",
      "1549      united utilities group plc               Status 429\n",
      "1550         veolia environnement sa               Status 429\n",
      "1551                     vistra corp               Status 429\n",
      "1552           waste connections inc               Status 429\n",
      "1553            waste management inc               Status 429\n",
      "\n",
      "[1554 rows x 3 columns]\n",
      "\n",
      "============================================================\n",
      "TOP 10 COMPANIES BY DISAGREEMENTS:\n",
      "                 company_name  total_disagreements\n",
      "218             volkswagen ag                   85\n",
      "358    berkshire hathaway inc                   56\n",
      "217                vivendi se                   46\n",
      "159           mcdonald's corp                   41\n",
      "169                opmobility                   41\n",
      "302    petroleo brasileiro sa                   40\n",
      "188                    seb sa                   39\n",
      "130  hermes international sca                   36\n",
      "294          exxon mobil corp                   36\n",
      "103         christian dior se                   28\n"
     ]
    }
   ],
   "source": [
    "# Check which companies had errors\n",
    "print(\"REMAINING ERRORS:\")\n",
    "print(df_errors[['company', 'ticker', 'error']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check companies with most disagreements\n",
    "print(\"TOP 10 COMPANIES BY DISAGREEMENTS:\")\n",
    "print(df_stats.nlargest(10, 'total_disagreements')[['company_name', 'total_disagreements']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "470eb387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR BREAKDOWN:\n",
      "error\n",
      "Status 429          1243\n",
      "No data returned     311\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "✓ Successfully processed: 371 empresas\n",
      "  - With disagreements: 243\n",
      "  - Zero disagreements: 128\n",
      "\n",
      "✗ Failed: 1554 empresas\n",
      "\n",
      "Total disagreements found: 1805\n"
     ]
    }
   ],
   "source": [
    "# Error breakdown\n",
    "print(\"ERROR BREAKDOWN:\")\n",
    "print(df_errors['error'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"✓ Successfully processed: {len(df_stats)} empresas\")\n",
    "print(f\"  - With disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"  - Zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")\n",
    "print(f\"\\n✗ Failed: {len(df_errors)} empresas\")\n",
    "print(f\"\\nTotal disagreements found: {len(df_disagreements)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "78b0ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR BREAKDOWN:\n",
      "error\n",
      "Status 429          1243\n",
      "No data returned     311\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "\n",
      "Error type distribution:\n",
      "error_type\n",
      "429      1243\n",
      "Other     311\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Error breakdown by type\n",
    "print(\"ERROR BREAKDOWN:\")\n",
    "print(df_errors['error'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check at what point 429 errors started\n",
    "df_errors['error_type'] = df_errors['error'].apply(lambda x: '429' if '429' in str(x) else 'Other')\n",
    "print(\"\\nError type distribution:\")\n",
    "print(df_errors['error_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38944daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_company_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = re.sub(r'[.,()&/]', '', name)\n",
    "    name = ' '.join(name.split())\n",
    "    return name.strip()\n",
    "\n",
    "print(f\"Total companies to process: {len(df_p80)}\")\n",
    "\n",
    "checkpoint_file = 'checkpoint_progress.csv'\n",
    "disagreements_file = 'checkpoint_disagreements.csv'\n",
    "stats_file = 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies already done\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100\n",
    "\n",
    "for idx, row in df_p80.iterrows():\n",
    "    company_name = row['Name']\n",
    "    ticker = row.get('Ticker', '')\n",
    "    \n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_p80) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_p80)} ({processed/len(df_p80)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        response = None\n",
    "        \n",
    "        if ticker and ticker.strip():\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/ticker/{ticker}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200 and 'companies' in response.json() and len(response.json()['companies']) > 0:\n",
    "                pass\n",
    "            else:\n",
    "                response = None\n",
    "        \n",
    "        if response is None:\n",
    "            clean_name = clean_company_name(company_name)\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/company/{clean_name}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        total_disagreements = 0\n",
    "        \n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            time.sleep(1.0)  # INCREASED from 0.1 to 1.0 seconds\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                if mgmt_rec is None or mgmt_rec == '' or pd.isna(mgmt_rec) or str(mgmt_rec) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                if nbim_vote is None or nbim_vote == '' or pd.isna(nbim_vote) or str(nbim_vote) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'ticker': ticker, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fbe2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint files exist:\n",
      "checkpoint_progress.csv: True\n",
      "checkpoint_disagreements.csv: True\n",
      "checkpoint_stats.csv: True\n",
      "\n",
      "Companies already processed: 600\n"
     ]
    }
   ],
   "source": [
    "# Verify checkpoint files exist\n",
    "print(\"Checkpoint files exist:\")\n",
    "print(f\"checkpoint_progress.csv: {os.path.exists('checkpoint_progress.csv')}\")\n",
    "print(f\"checkpoint_disagreements.csv: {os.path.exists('checkpoint_disagreements.csv')}\")\n",
    "print(f\"checkpoint_stats.csv: {os.path.exists('checkpoint_stats.csv')}\")\n",
    "\n",
    "# Verify how many companies already processed\n",
    "if os.path.exists('checkpoint_progress.csv'):\n",
    "    processed = pd.read_csv('checkpoint_progress.csv')\n",
    "    print(f\"\\nCompanies already processed: {len(processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab6d28",
   "metadata": {},
   "source": [
    "Continue with the execution after revising the errors, checking the number of analyzed companies and slowing the time between API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f8598f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies to process: 1925\n",
      "\n",
      "✓ RESUMING from checkpoint: 600 companies already done\n",
      "Progress: 650/1925 (33.8%) - Est. 0.8 min remaining\n",
      "Progress: 700/1925 (36.4%) - Est. 1.5 min remaining\n",
      "Progress: 750/1925 (39.0%) - Est. 1.9 min remaining\n",
      "Progress: 800/1925 (41.6%) - Est. 2.2 min remaining\n",
      "Progress: 850/1925 (44.2%) - Est. 2.4 min remaining\n",
      "Progress: 900/1925 (46.8%) - Est. 2.8 min remaining\n",
      "Progress: 950/1925 (49.4%) - Est. 2.9 min remaining\n",
      "Progress: 1000/1925 (51.9%) - Est. 3.0 min remaining\n",
      "Progress: 1050/1925 (54.5%) - Est. 3.0 min remaining\n",
      "Progress: 1100/1925 (57.1%) - Est. 3.0 min remaining\n",
      "Progress: 1150/1925 (59.7%) - Est. 3.0 min remaining\n",
      "Progress: 1200/1925 (62.3%) - Est. 2.9 min remaining\n",
      "Progress: 1250/1925 (64.9%) - Est. 2.8 min remaining\n",
      "Progress: 1300/1925 (67.5%) - Est. 2.7 min remaining\n",
      "Progress: 1350/1925 (70.1%) - Est. 2.5 min remaining\n",
      "Progress: 1400/1925 (72.7%) - Est. 2.3 min remaining\n",
      "Progress: 1450/1925 (75.3%) - Est. 2.1 min remaining\n",
      "Progress: 1500/1925 (77.9%) - Est. 2.0 min remaining\n",
      "Progress: 1550/1925 (80.5%) - Est. 1.8 min remaining\n",
      "Progress: 1600/1925 (83.1%) - Est. 1.5 min remaining\n",
      "Progress: 1650/1925 (85.7%) - Est. 1.3 min remaining\n",
      "Progress: 1700/1925 (88.3%) - Est. 1.1 min remaining\n",
      "Progress: 1750/1925 (90.9%) - Est. 0.9 min remaining\n",
      "Progress: 1800/1925 (93.5%) - Est. 0.6 min remaining\n",
      "Progress: 1850/1925 (96.1%) - Est. 0.4 min remaining\n",
      "Progress: 1900/1925 (98.7%) - Est. 0.1 min remaining\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Total companies processed: 1925\n",
      "Total errors: 1325\n",
      "Total disagreements found: 1614\n",
      "\n",
      "Companies with disagreements: 215\n",
      "Companies with zero disagreements: 114\n"
     ]
    }
   ],
   "source": [
    "def clean_company_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    # Remove punctuation and parentheses\n",
    "    name = re.sub(r'[.,()&/]', '', name)\n",
    "    # Replace multiple spaces with single space\n",
    "    name = ' '.join(name.split())\n",
    "    return name.strip()\n",
    "\n",
    "print(f\"Total companies to process: {len(df_p80)}\")\n",
    "\n",
    "checkpoint_file = 'checkpoint_progress.csv'\n",
    "disagreements_file = 'checkpoint_disagreements.csv'\n",
    "stats_file = 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies already done\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100\n",
    "\n",
    "for idx, row in df_p80.iterrows():\n",
    "    company_name = row['Name']\n",
    "    ticker = row.get('Ticker', '')\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    # Progress update every 50 companies\n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_p80) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_p80)} ({processed/len(df_p80)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        response = None\n",
    "        \n",
    "        # Try 1: Search by ticker (more reliable)\n",
    "        if ticker and ticker.strip():\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/ticker/{ticker}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200 and 'companies' in response.json() and len(response.json()['companies']) > 0:\n",
    "                pass\n",
    "            else:\n",
    "                response = None\n",
    "        \n",
    "        # Try 2: Search by company name (if ticker failed or not available)\n",
    "        if response is None:\n",
    "            clean_name = clean_company_name(company_name)\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/company/{clean_name}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "        \n",
    "        # If both failed, log error and continue\n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        # Check if companies array exists\n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        # Filter meetings from 2020 onwards\n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        # Stats for this company\n",
    "        total_disagreements = 0\n",
    "        \n",
    "        # Step 2: Process each meeting\n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            # Rate limiting: 1 second delay between requests\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            # Identify disagreements\n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                # SKIP if management_rec is None, empty, or string \"None\"\n",
    "                if mgmt_rec is None or mgmt_rec == '' or pd.isna(mgmt_rec) or str(mgmt_rec) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                # SKIP if nbim_vote is None, empty, or string \"None\"\n",
    "                if nbim_vote is None or nbim_vote == '' or pd.isna(nbim_vote) or str(nbim_vote) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                # DISAGREEMENT: when different\n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    # Extract rationale info\n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    # Store disagreement\n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        # Store company-level stats\n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        # CHECKPOINT: Save progress every 100 companies\n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'ticker': ticker, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "# Final save\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8700257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMAINING ERRORS:\n",
      "                               company ticker       error\n",
      "0                           allianz se         Status 429\n",
      "1                    allstate corp/the         Status 429\n",
      "2      american financial group inc/oh         Status 429\n",
      "3     american international group inc         Status 429\n",
      "4             ameriprise financial inc         Status 429\n",
      "...                                ...    ...         ...\n",
      "1320        united utilities group plc         Status 429\n",
      "1321           veolia environnement sa         Status 429\n",
      "1322                       vistra corp         Status 429\n",
      "1323             waste connections inc         Status 429\n",
      "1324              waste management inc         Status 429\n",
      "\n",
      "[1325 rows x 3 columns]\n",
      "\n",
      "============================================================\n",
      "TOP 10 COMPANIES BY DISAGREEMENTS:\n",
      "                 company_name  total_disagreements\n",
      "218             volkswagen ag                   85\n",
      "217                vivendi se                   46\n",
      "159           mcdonald's corp                   41\n",
      "169                opmobility                   41\n",
      "302    petroleo brasileiro sa                   40\n",
      "188                    seb sa                   39\n",
      "130  hermes international sca                   36\n",
      "294          exxon mobil corp                   36\n",
      "103         christian dior se                   28\n",
      "149      las vegas sands corp                   28\n"
     ]
    }
   ],
   "source": [
    "# Check which companies had errors\n",
    "print(\"REMAINING ERRORS:\")\n",
    "print(df_errors[['company', 'ticker', 'error']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check companies with most disagreements\n",
    "print(\"TOP 10 COMPANIES BY DISAGREEMENTS:\")\n",
    "print(df_stats.nlargest(10, 'total_disagreements')[['company_name', 'total_disagreements']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3599e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies in checkpoint: 1925\n",
      "Companies in df_stats: 329\n",
      "\n",
      "ERROR BREAKDOWN:\n",
      "error\n",
      "Status 429    1325\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Companies processed in this run: 0\n"
     ]
    }
   ],
   "source": [
    "# Check how many companies were actually processed in this run\n",
    "print(f\"Companies in checkpoint: {len(processed_companies)}\")\n",
    "print(f\"Companies in df_stats: {len(df_stats)}\")\n",
    "\n",
    "# Check error breakdown\n",
    "print(\"\\nERROR BREAKDOWN:\")\n",
    "print(df_errors['error'].value_counts())\n",
    "\n",
    "# Check if we processed any new companies\n",
    "if os.path.exists('checkpoint_progress.csv'):\n",
    "    checkpoint_before = 600  # We had 600 before\n",
    "    checkpoint_now = len(pd.read_csv('checkpoint_progress.csv'))\n",
    "    print(f\"\\nCompanies processed in this run: {checkpoint_now - checkpoint_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bae1ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies with actual data: 329\n",
      "Total disagreements: 1614\n",
      "\n",
      "Companies with disagreements: 215\n",
      "Companies with zero disagreements: 114\n",
      "\n",
      "Data coverage: 17.1% of total sample\n"
     ]
    }
   ],
   "source": [
    "# Check actual successful companies\n",
    "print(f\"Companies with actual data: {len(df_stats)}\")\n",
    "print(f\"Total disagreements: {len(df_disagreements)}\")\n",
    "\n",
    "# Check companies with disagreements\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")\n",
    "\n",
    "# See if we have enough data to work with\n",
    "print(f\"\\nData coverage: {len(df_stats)/len(df_p80)*100:.1f}% of total sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "38800eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVERAGE ANALYSIS:\n",
      "============================================================\n",
      "Market value coverage: 12.8%\n",
      "\n",
      "Top 500 companies coverage: 273/500\n",
      "Top 1000 companies coverage: 329/1000\n",
      "\n",
      "ESG_any companies coverage: 208/901\n",
      "\n",
      "INDUSTRY COVERAGE (processed companies):\n",
      "Industry\n",
      "Consumer Discretionary    146\n",
      "Basic Materials            82\n",
      "Consumer Staples           56\n",
      "Energy                     35\n",
      "Financials                 10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "DISAGREEMENTS:\n",
      "Total: 1614\n",
      "Average per company: 4.9\n"
     ]
    }
   ],
   "source": [
    "# Check if we have the largest companies\n",
    "print(\"COVERAGE ANALYSIS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate market value coverage\n",
    "total_market_value = df_p80['Market_Value_USD'].sum()\n",
    "processed_names = df_stats['company_name'].tolist()\n",
    "processed_market_value = df_p80[df_p80['Name'].isin(processed_names)]['Market_Value_USD'].sum()\n",
    "\n",
    "print(f\"Market value coverage: {processed_market_value/total_market_value*100:.1f}%\")\n",
    "\n",
    "# Check if we have top companies\n",
    "df_p80['processed'] = df_p80['Name'].isin(processed_names)\n",
    "print(f\"\\nTop 500 companies coverage: {df_p80.head(500)['processed'].sum()}/500\")\n",
    "print(f\"Top 1000 companies coverage: {df_p80.head(1000)['processed'].sum()}/1000\")\n",
    "\n",
    "# Check ESG_any coverage\n",
    "if 'ESG_any' in df_p80.columns:\n",
    "    esg_companies = df_p80[df_p80['ESG_any'] == 1]['Name'].tolist()\n",
    "    esg_processed = len([c for c in esg_companies if c in processed_names])\n",
    "    print(f\"\\nESG_any companies coverage: {esg_processed}/{len(esg_companies)}\")\n",
    "\n",
    "# Check industry distribution\n",
    "print(\"\\nINDUSTRY COVERAGE (processed companies):\")\n",
    "processed_df = df_p80[df_p80['Name'].isin(processed_names)]\n",
    "print(processed_df['Industry'].value_counts().head(10))\n",
    "\n",
    "# Check disaggregments stats\n",
    "print(f\"\\nDISAGREEMENTS:\")\n",
    "print(f\"Total: {len(df_disagreements)}\")\n",
    "print(f\"Average per company: {len(df_disagreements)/len(df_stats):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71f89dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved partial data with timestamp: 20251209_1313\n",
      "  - 1614 disagreements\n",
      "  - 329 companies\n"
     ]
    }
   ],
   "source": [
    "#Save current data with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "\n",
    "# Save dataframes\n",
    "df_disagreements.to_csv(f'disagreements_partial_{timestamp}.csv', index=False)\n",
    "df_stats.to_csv(f'company_stats_partial_{timestamp}.csv', index=False)\n",
    "df_errors.to_csv(f'errors_partial_{timestamp}.csv', index=False)\n",
    "\n",
    "print(f\"✓ Saved partial data with timestamp: {timestamp}\")\n",
    "print(f\"  - {len(df_disagreements)} disagreements\")\n",
    "print(f\"  - {len(df_stats)} companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41f6c837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRELIMINARY ANALYSIS (329 companies)\n",
      "============================================================\n",
      "\n",
      "1. DISAGREEMENT DISTRIBUTION:\n",
      "Companies with disagreements: 215 (65.3%)\n",
      "Companies with zero: 114 (34.7%)\n",
      "\n",
      "Total disagreements: 1614\n",
      "Average per company: 4.9\n",
      "Median: 2\n",
      "\n",
      "2. TOP 10 COMPANIES BY DISAGREEMENTS:\n",
      "                 company_name                Industry  total_disagreements\n",
      "218             volkswagen ag  Consumer Discretionary                   85\n",
      "217                vivendi se  Consumer Discretionary                   46\n",
      "159           mcdonald's corp  Consumer Discretionary                   41\n",
      "169                opmobility  Consumer Discretionary                   41\n",
      "302    petroleo brasileiro sa                  Energy                   40\n",
      "188                    seb sa  Consumer Discretionary                   39\n",
      "130  hermes international sca  Consumer Discretionary                   36\n",
      "294          exxon mobil corp                  Energy                   36\n",
      "103         christian dior se  Consumer Discretionary                   28\n",
      "149      las vegas sands corp  Consumer Discretionary                   28\n",
      "\n",
      "3. DISAGREEMENTS BY INDUSTRY:\n",
      "                        Total  Avg_per_company  N_companies\n",
      "Industry                                                   \n",
      "Consumer Discretionary    870             5.96          146\n",
      "Basic Materials           259             3.16           82\n",
      "Consumer Staples          235             4.20           56\n",
      "Energy                    229             6.54           35\n",
      "Financials                 21             2.10           10\n",
      "\n",
      "4. ESG_ANY COMPARISON:\n",
      "         Avg_disagreements  Total  N_companies\n",
      "ESG_any                                       \n",
      "0                     4.74    573          121\n",
      "1                     5.00   1041          208\n"
     ]
    }
   ],
   "source": [
    "# Merge with original df_p80 to get additional info\n",
    "df_analysis = df_stats.merge(\n",
    "    df_p80[['Name', 'Industry', 'Market_Value_USD', 'ESG_any']], \n",
    "    left_on='company_name', \n",
    "    right_on='Name', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"PRELIMINARY ANALYSIS (329 companies)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Disagreement distribution\n",
    "print(\"\\n1. DISAGREEMENT DISTRIBUTION:\")\n",
    "print(f\"Companies with disagreements: {(df_analysis['total_disagreements'] > 0).sum()} ({(df_analysis['total_disagreements'] > 0).sum()/len(df_analysis)*100:.1f}%)\")\n",
    "print(f\"Companies with zero: {(df_analysis['total_disagreements'] == 0).sum()} ({(df_analysis['total_disagreements'] == 0).sum()/len(df_analysis)*100:.1f}%)\")\n",
    "print(f\"\\nTotal disagreements: {df_analysis['total_disagreements'].sum()}\")\n",
    "print(f\"Average per company: {df_analysis['total_disagreements'].mean():.1f}\")\n",
    "print(f\"Median: {df_analysis['total_disagreements'].median():.0f}\")\n",
    "\n",
    "# Top companies by disagreements\n",
    "print(\"\\n2. TOP 10 COMPANIES BY DISAGREEMENTS:\")\n",
    "print(df_analysis.nlargest(10, 'total_disagreements')[['company_name', 'Industry', 'total_disagreements']])\n",
    "\n",
    "# Industry breakdown\n",
    "print(\"\\n3. DISAGREEMENTS BY INDUSTRY:\")\n",
    "industry_stats = df_analysis.groupby('Industry').agg({\n",
    "    'total_disagreements': ['sum', 'mean', 'count']\n",
    "}).round(2)\n",
    "industry_stats.columns = ['Total', 'Avg_per_company', 'N_companies']\n",
    "print(industry_stats.sort_values('Total', ascending=False))\n",
    "\n",
    "# ESG_any comparison\n",
    "print(\"\\n4. ESG_ANY COMPARISON:\")\n",
    "if 'ESG_any' in df_analysis.columns:\n",
    "    esg_comparison = df_analysis.groupby('ESG_any').agg({\n",
    "        'total_disagreements': ['mean', 'sum', 'count']\n",
    "    }).round(2)\n",
    "    esg_comparison.columns = ['Avg_disagreements', 'Total', 'N_companies']\n",
    "    print(esg_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ac5c5a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TECH SECTOR VERIFICATION:\n",
      "============================================================\n",
      "\n",
      "All industries present:\n",
      "Industry\n",
      "Consumer Discretionary    146\n",
      "Basic Materials            82\n",
      "Consumer Staples           56\n",
      "Energy                     35\n",
      "Financials                 10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Tech companies found by name:\n",
      "                        company_name         Industry  total_disagreements\n",
      "74  triple flag precious metals corp  Basic Materials                    1\n",
      "81      wheaton precious metals corp  Basic Materials                    2\n",
      "\n",
      "============================================================\n",
      "TECH IN ORIGINAL SAMPLE:\n",
      "Industry\n",
      "Industrials               368\n",
      "Financials                353\n",
      "Consumer Discretionary    296\n",
      "Technology                218\n",
      "Health Care               167\n",
      "Consumer Staples          119\n",
      "Basic Materials           113\n",
      "Real Estate               113\n",
      "Utilities                  67\n",
      "Energy                     58\n",
      "Telecommunications         53\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if we have tech companies\n",
    "print(\"TECH SECTOR VERIFICATION:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check all unique industries\n",
    "print(\"\\nAll industries present:\")\n",
    "print(df_analysis['Industry'].value_counts())\n",
    "\n",
    "# Search for tech-related companies by name\n",
    "tech_keywords = ['microsoft', 'apple', 'nvidia', 'alphabet', 'google', 'meta', 'amazon', 'tesla']\n",
    "df_analysis['is_tech_name'] = df_analysis['company_name'].str.lower().apply(\n",
    "    lambda x: any(keyword in str(x) for keyword in tech_keywords)\n",
    ")\n",
    "\n",
    "print(\"\\n\\nTech companies found by name:\")\n",
    "tech_companies = df_analysis[df_analysis['is_tech_name']]\n",
    "if len(tech_companies) > 0:\n",
    "    print(tech_companies[['company_name', 'Industry', 'total_disagreements']])\n",
    "else:\n",
    "    print(\"❌ NO TECH COMPANIES FOUND IN 329 PROCESSED\")\n",
    "\n",
    "# Check original df_p80 to see tech distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TECH IN ORIGINAL SAMPLE:\")\n",
    "if 'Industry' in df_p80.columns:\n",
    "    print(df_p80['Industry'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "848185d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TECH COMPANIES POSITION IN RANKING:\n",
      "============================================================\n",
      "\n",
      "Tech companies in sample: 218\n",
      "\n",
      "Tech company positions (first 20):\n",
      "      rank                           Name  Market_Value_USD    Industry\n",
      "1587  1588                      adobe inc        2512307262  Technology\n",
      "1588  1589     advanced micro devices inc        2837356134  Technology\n",
      "1589  1590                 advantest corp         798576473  Technology\n",
      "1590  1591        akamai technologies inc         474499181  Technology\n",
      "1591  1592        alchip technologies ltd         209533519  Technology\n",
      "1592  1593       allegro microsystems inc          26926405  Technology\n",
      "1593  1594                   alphabet inc       29271691564  Technology\n",
      "1594  1595            amadeus it group sa         813691936  Technology\n",
      "1595  1596                  amphenol corp        1389817288  Technology\n",
      "1596  1597             analog devices inc        1776064894  Technology\n",
      "1597  1598                      ansys inc         622416691  Technology\n",
      "1598  1599                      apple inc       46210392003  Technology\n",
      "1599  1600          applied materials inc        1560706117  Technology\n",
      "1600  1601                  applovin corp         810579844  Technology\n",
      "1601  1602  ase technology holding co ltd         154104242  Technology\n",
      "1602  1603   asia vital components co ltd         119303251  Technology\n",
      "1603  1604           asm international nv        1221051057  Technology\n",
      "1604  1605         asmedia technology inc         123697327  Technology\n",
      "1605  1606                asml holding nv        7019542678  Technology\n",
      "1606  1607                astera labs inc         179228559  Technology\n",
      "\n",
      "Lowest tech rank: 1588\n",
      "Highest tech rank: 1805\n",
      "Median tech rank: 1696\n",
      "\n",
      "\n",
      "Companies processed: positions 1-329\n",
      "Tech starts at position: 1588\n",
      "\n",
      "❌ We stopped BEFORE reaching tech companies!\n"
     ]
    }
   ],
   "source": [
    "# Check where tech companies are in the ranking\n",
    "print(\"TECH COMPANIES POSITION IN RANKING:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_p80_ranked = df_p80.reset_index(drop=True)\n",
    "df_p80_ranked['rank'] = df_p80_ranked.index + 1\n",
    "\n",
    "tech_companies = df_p80_ranked[df_p80_ranked['Industry'] == 'Technology']\n",
    "\n",
    "print(f\"\\nTech companies in sample: {len(tech_companies)}\")\n",
    "print(f\"\\nTech company positions (first 20):\")\n",
    "print(tech_companies.head(20)[['rank', 'Name', 'Market_Value_USD', 'Industry']])\n",
    "\n",
    "print(f\"\\nLowest tech rank: {tech_companies['rank'].min()}\")\n",
    "print(f\"Highest tech rank: {tech_companies['rank'].max()}\")\n",
    "print(f\"Median tech rank: {tech_companies['rank'].median():.0f}\")\n",
    "\n",
    "# Companies we processed\n",
    "print(f\"\\n\\nCompanies processed: positions 1-329\")\n",
    "print(f\"Tech starts at position: {tech_companies['rank'].min()}\")\n",
    "print(f\"\\n❌ We stopped BEFORE reaching tech companies!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4f6688e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies already processed: 329\n",
      "✓ Saved list of processed companies\n",
      "\n",
      "STATUS SUMMARY:\n",
      "Total companies: 1925\n",
      "Already processed: 329\n",
      "Remaining to process: 1596\n",
      "\n",
      "NEXT 20 COMPANIES TO PROCESS (largest remaining):\n",
      "                                         Name  Market_Value_USD  \\\n",
      "0                                   apple inc       46210392003   \n",
      "1                              microsoft corp       43758827987   \n",
      "2                                 nvidia corp       42973911250   \n",
      "3                                alphabet inc       29271691564   \n",
      "4                              amazon.com inc       26979313029   \n",
      "5                          meta platforms inc       19750530468   \n",
      "6                                broadcom inc       16712325272   \n",
      "7   taiwan semiconductor manufacturing co ltd       15368120434   \n",
      "8                                   tesla inc       14211259233   \n",
      "9                      berkshire hathaway inc        9483089298   \n",
      "10                             eli lilly & co        8279768708   \n",
      "11                        jpmorgan chase & co        8171466040   \n",
      "12                                     sap se        7156324287   \n",
      "13                            asml holding nv        7019542678   \n",
      "15                           novo nordisk a/s        6782991606   \n",
      "16                       tencent holdings ltd        6672234732   \n",
      "17                     unitedhealth group inc        6354521253   \n",
      "19                             mastercard inc        5951922338   \n",
      "21                               ubs group ag        5582607488   \n",
      "22                           roche holding ag        5272273510   \n",
      "\n",
      "                  Industry  \n",
      "0               Technology  \n",
      "1               Technology  \n",
      "2               Technology  \n",
      "3               Technology  \n",
      "4   Consumer Discretionary  \n",
      "5               Technology  \n",
      "6               Technology  \n",
      "7               Technology  \n",
      "8   Consumer Discretionary  \n",
      "9               Financials  \n",
      "10             Health Care  \n",
      "11              Financials  \n",
      "12              Technology  \n",
      "13              Technology  \n",
      "15             Health Care  \n",
      "16              Technology  \n",
      "17             Health Care  \n",
      "19             Industrials  \n",
      "21              Financials  \n",
      "22             Health Care  \n",
      "\n",
      "✓ Saved sorted df_p80 with processing status\n"
     ]
    }
   ],
   "source": [
    "# 1. Save list of companies already processed (329)\n",
    "processed_companies_list = df_stats['company_name'].tolist()\n",
    "print(f\"Companies already processed: {len(processed_companies_list)}\")\n",
    "\n",
    "# Save to file\n",
    "import json\n",
    "with open('companies_already_processed.json', 'w') as f:\n",
    "    json.dump(processed_companies_list, f)\n",
    "print(\"✓ Saved list of processed companies\")\n",
    "\n",
    "# 2. Re-order df_p80 correctly by market value\n",
    "df_p80_sorted = df_p80.sort_values('Market_Value_USD', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 3. Mark which companies are already done\n",
    "df_p80_sorted['already_processed'] = df_p80_sorted['Name'].isin(processed_companies_list)\n",
    "\n",
    "print(\"\\nSTATUS SUMMARY:\")\n",
    "print(f\"Total companies: {len(df_p80_sorted)}\")\n",
    "print(f\"Already processed: {df_p80_sorted['already_processed'].sum()}\")\n",
    "print(f\"Remaining to process: {(~df_p80_sorted['already_processed']).sum()}\")\n",
    "\n",
    "# 4. Show next companies to process (should be tech giants)\n",
    "print(\"\\nNEXT 20 COMPANIES TO PROCESS (largest remaining):\")\n",
    "next_to_process = df_p80_sorted[~df_p80_sorted['already_processed']].head(20)\n",
    "print(next_to_process[['Name', 'Market_Value_USD', 'Industry']])\n",
    "\n",
    "# 5. Save correctly sorted df\n",
    "df_p80_sorted.to_csv('p80_companies_sorted_with_status.csv', index=False)\n",
    "print(\"\\n✓ Saved sorted df_p80 with processing status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05327eb0",
   "metadata": {},
   "source": [
    "Reorganizing the project's folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7e82b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REORGANIZING FILES...\n",
      "============================================================\n",
      "✓ Moved checkpoint_progress.csv → temp/\n",
      "✓ Moved checkpoint_disagreements.csv → temp/\n",
      "✓ Moved checkpoint_stats.csv → temp/\n",
      "✓ Moved disagreements_partial_20251209_1313.csv → datasets/voting_data/\n",
      "✓ Moved company_stats_partial_20251209_1313.csv → datasets/voting_data/\n",
      "✓ Moved errors_partial_20251209_1313.csv → datasets/voting_data/\n",
      "✓ Moved companies_already_processed.json → datasets/\n",
      "✓ Moved p80_companies_sorted_with_status.csv → datasets/\n",
      "\n",
      "============================================================\n",
      "REORGANIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Current structure:\n",
      "  /notebooks/temp/ → Temporary checkpoints\n",
      "  /datasets/ → Master data + sorted p80\n",
      "  /datasets/voting_data/ → Partial results\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../datasets/\"\n",
    "TEMP_PATH = \"./temp/\"\n",
    "VOTING_DATA_PATH = \"../datasets/voting_data/\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(TEMP_PATH, exist_ok=True)\n",
    "os.makedirs(VOTING_DATA_PATH, exist_ok=True)\n",
    "\n",
    "print(\"REORGANIZING FILES...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Move checkpoints to temp folder\n",
    "checkpoint_files = ['checkpoint_progress.csv', 'checkpoint_disagreements.csv', 'checkpoint_stats.csv']\n",
    "for file in checkpoint_files:\n",
    "    if os.path.exists(file):\n",
    "        shutil.move(file, TEMP_PATH + file)\n",
    "        print(f\"✓ Moved {file} → temp/\")\n",
    "\n",
    "# 2. Move final data files to datasets/voting_data/\n",
    "data_files = [\n",
    "    'disagreements_partial_20251209_1313.csv',\n",
    "    'company_stats_partial_20251209_1313.csv', \n",
    "    'errors_partial_20251209_1313.csv'\n",
    "]\n",
    "for file in data_files:\n",
    "    if os.path.exists(file):\n",
    "        shutil.move(file, VOTING_DATA_PATH + file)\n",
    "        print(f\"✓ Moved {file} → datasets/voting_data/\")\n",
    "\n",
    "# 3. Move companies list to datasets\n",
    "if os.path.exists('companies_already_processed.json'):\n",
    "    shutil.move('companies_already_processed.json', DATA_PATH + 'companies_already_processed.json')\n",
    "    print(f\"✓ Moved companies_already_processed.json → datasets/\")\n",
    "\n",
    "# 4. Move sorted p80 to datasets\n",
    "if os.path.exists('p80_companies_sorted_with_status.csv'):\n",
    "    shutil.move('p80_companies_sorted_with_status.csv', DATA_PATH + 'p80_companies_sorted_with_status.csv')\n",
    "    print(f\"✓ Moved p80_companies_sorted_with_status.csv → datasets/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REORGANIZATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nCurrent structure:\")\n",
    "print(\"  /notebooks/temp/ → Temporary checkpoints\")\n",
    "print(\"  /datasets/ → Master data + sorted p80\")\n",
    "print(\"  /datasets/voting_data/ → Partial results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46107a09",
   "metadata": {},
   "source": [
    "# Execute next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies in sample: 1925\n",
      "Already processed: 329\n",
      "To process today: 1596\n",
      "\n",
      "Starting with: apple inc\n",
      "\n",
      "✓ RESUMING from checkpoint: 600 companies in this session\n",
      "Progress: 650/1596 (40.7%) - Est. 8.7 min remaining\n",
      "Progress: 700/1596 (43.9%) - Est. 14.5 min remaining\n",
      "Progress: 750/1596 (47.0%) - Est. 18.1 min remaining\n",
      "Progress: 800/1596 (50.1%) - Est. 21.4 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 800 companies\n",
      "Progress: 850/1596 (53.3%) - Est. 22.7 min remaining\n",
      "Progress: 900/1596 (56.4%) - Est. 23.1 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 900 companies\n",
      "Progress: 950/1596 (59.5%) - Est. 23.7 min remaining\n",
      "Progress: 1000/1596 (62.7%) - Est. 23.2 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 1000 companies\n",
      "Progress: 1050/1596 (65.8%) - Est. 22.9 min remaining\n",
      "Progress: 1100/1596 (68.9%) - Est. 21.9 min remaining\n",
      "Progress: 1150/1596 (72.1%) - Est. 20.3 min remaining\n",
      "Progress: 1200/1596 (75.2%) - Est. 18.4 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 1200 companies\n",
      "Progress: 1250/1596 (78.3%) - Est. 16.7 min remaining\n",
      "Progress: 1300/1596 (81.5%) - Est. 15.1 min remaining\n",
      "Progress: 1350/1596 (84.6%) - Est. 13.0 min remaining\n",
      "Progress: 1400/1596 (87.7%) - Est. 10.5 min remaining\n",
      "Progress: 1450/1596 (90.9%) - Est. 8.0 min remaining\n",
      "Progress: 1500/1596 (94.0%) - Est. 5.3 min remaining\n",
      "Progress: 1550/1596 (97.1%) - Est. 2.6 min remaining\n",
      "Progress: 1600/1596 (100.3%) - Est. -0.2 min remaining\n",
      "\n",
      "✓ Checkpoint saved at 1600 companies\n",
      "Progress: 1650/1596 (103.4%) - Est. -3.1 min remaining\n",
      "Progress: 1700/1596 (106.5%) - Est. -6.0 min remaining\n",
      "Progress: 1750/1596 (109.6%) - Est. -8.6 min remaining\n",
      "Progress: 1800/1596 (112.8%) - Est. -11.2 min remaining\n",
      "Progress: 1850/1596 (115.9%) - Est. -13.6 min remaining\n",
      "Progress: 1900/1596 (119.0%) - Est. -15.8 min remaining\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Total companies processed in this session: 1925\n",
      "Total errors: 748\n",
      "Total disagreements found: 3912\n",
      "\n",
      "Companies with disagreements: 592\n",
      "Companies with zero disagreements: 314\n",
      "\n",
      "Data saved to: ../datasets/voting_data/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SETUP: Paths and imports\n",
    "#It has all the imports as it was from scratch\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API credentials\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NBIM_API_KEY')\n",
    "BASE_URL = os.getenv('NBIM_BASE_URL')\n",
    "\n",
    "headers = {'x-api-key': API_KEY}\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../datasets/\"\n",
    "TEMP_PATH = \"./temp/\"\n",
    "VOTING_DATA_PATH = \"../datasets/voting_data/\"\n",
    "\n",
    "# Create directories if needed\n",
    "os.makedirs(TEMP_PATH, exist_ok=True)\n",
    "os.makedirs(VOTING_DATA_PATH, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Load sorted df_p80 with processing status\n",
    "df_p80 = pd.read_csv(DATA_PATH + 'p80_companies_sorted_with_status.csv')\n",
    "\n",
    "# Filter only unprocessed companies\n",
    "df_to_process = df_p80[~df_p80['already_processed']].copy()\n",
    "\n",
    "print(f\"Total companies in sample: {len(df_p80)}\")\n",
    "print(f\"Already processed: {df_p80['already_processed'].sum()}\")\n",
    "print(f\"To process today: {len(df_to_process)}\")\n",
    "print(f\"\\nStarting with: {df_to_process.iloc[0]['Name']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def clean_company_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = re.sub(r'[.,()&/]', '', name)\n",
    "    name = ' '.join(name.split())\n",
    "    return name.strip()\n",
    "\n",
    "# =============================================================================\n",
    "# CHECKPOINT SETUP\n",
    "# =============================================================================\n",
    "\n",
    "checkpoint_file = TEMP_PATH + 'checkpoint_progress.csv'\n",
    "disagreements_file = TEMP_PATH + 'checkpoint_disagreements.csv'\n",
    "stats_file = TEMP_PATH + 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies in this session\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXTRACTION LOOP\n",
    "# =============================================================================\n",
    "\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100\n",
    "\n",
    "for idx, row in df_to_process.iterrows():\n",
    "    company_name = row['Name']\n",
    "    ticker = row.get('Ticker', '')\n",
    "    \n",
    "    # Skip if already processed in this session\n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    # Progress update every 50 companies\n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_to_process) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_to_process)} ({processed/len(df_to_process)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        response = None\n",
    "        \n",
    "        # Try 1: Search by ticker\n",
    "        if ticker and ticker.strip():\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/ticker/{ticker}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200 and 'companies' in response.json() and len(response.json()['companies']) > 0:\n",
    "                pass\n",
    "            else:\n",
    "                response = None\n",
    "        \n",
    "        # Try 2: Search by company name\n",
    "        if response is None:\n",
    "            clean_name = clean_company_name(company_name)\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/company/{clean_name}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "        \n",
    "        # If both failed, log error and continue\n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        # Check if companies array exists\n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        # Filter meetings from 2020 onwards\n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        total_disagreements = 0\n",
    "        \n",
    "        # Process each meeting\n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            # Rate limiting: 1 second delay\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            # Identify disagreements\n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                # SKIP if management_rec is None, empty, or string \"None\"\n",
    "                if mgmt_rec is None or mgmt_rec == '' or pd.isna(mgmt_rec) or str(mgmt_rec) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                # SKIP if nbim_vote is None, empty, or string \"None\"\n",
    "                if nbim_vote is None or nbim_vote == '' or pd.isna(nbim_vote) or str(nbim_vote) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                # DISAGREEMENT: when different\n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    # Extract rationale info\n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    # Store disagreement\n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        # Store company-level stats\n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        # CHECKPOINT: Save progress every 100 companies\n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'ticker': ticker, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SAVE\n",
    "# =============================================================================\n",
    "\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "# Save to voting_data folder with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "df_disagreements.to_csv(VOTING_DATA_PATH + f'disagreements_{timestamp}.csv', index=False)\n",
    "df_stats.to_csv(VOTING_DATA_PATH + f'company_stats_{timestamp}.csv', index=False)\n",
    "df_errors.to_csv(VOTING_DATA_PATH + f'errors_{timestamp}.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed in this session: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")\n",
    "print(f\"\\nData saved to: {VOTING_DATA_PATH}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "UPDATED P80 STATUS FILE\n",
      "============================================================\n",
      "Companies marked as processed: 906\n",
      "Companies remaining: 1019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# UPDATE P80 STATUS AFTER EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "# Load latest stats to see which companies were processed\n",
    "stats_files = glob.glob(VOTING_DATA_PATH + 'company_stats_*.csv')\n",
    "latest_stats = max(stats_files, key=os.path.getctime)\n",
    "df_stats_final = pd.read_csv(latest_stats)\n",
    "\n",
    "# Update df_p80 with newly processed companies\n",
    "newly_processed = df_stats_final['company_name'].tolist()\n",
    "df_p80['already_processed'] = df_p80['Name'].isin(newly_processed)\n",
    "\n",
    "# Save updated df_p80\n",
    "df_p80.to_csv(DATA_PATH + 'p80_companies_sorted_with_status.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UPDATED P80 STATUS FILE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Companies marked as processed: {df_p80['already_processed'].sum()}\")\n",
    "print(f\"Companies remaining: {(~df_p80['already_processed']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff6389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies in checkpoint: 1925\n",
      "Companies in df_stats: 906\n",
      "\n",
      "ERROR BREAKDOWN:\n",
      "error\n",
      "No data returned    509\n",
      "Status 429          239\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many companies were actually processed in this run\n",
    "print(f\"Companies in checkpoint: {len(processed_companies)}\")\n",
    "print(f\"Companies in df_stats: {len(df_stats)}\")\n",
    "\n",
    "# Check error breakdown\n",
    "print(\"\\nERROR BREAKDOWN:\")\n",
    "print(df_errors['error'].value_counts())\n",
    "\n",
    "# Check if we processed any new companies\n",
    "if os.path.exists('checkpoint_progress.csv'):\n",
    "    checkpoint_before = 600  # We had 600 before\n",
    "    checkpoint_now = len(pd.read_csv('checkpoint_progress.csv'))\n",
    "    print(f\"\\nCompanies processed in this run: {checkpoint_now - checkpoint_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f996a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No stats files found!\n",
      "TECH GIANTS STATUS:\n",
      "============================================================\n",
      "✅ apple inc                      → 10 disagreements\n",
      "✅ microsoft corp                 → 17 disagreements\n",
      "✅ nvidia corp                    → 0 disagreements\n",
      "✅ alphabet inc                   → 39 disagreements\n",
      "❌ meta platforms inc             → NOT FOUND\n",
      "❌ amazon.com inc                 → NOT FOUND\n",
      "✅ broadcom inc                   → 4 disagreements\n",
      "❌ tesla inc                      → NOT FOUND\n",
      "✅ asml holding nv                → 0 disagreements\n",
      "✅ sap se                         → 0 disagreements\n",
      "\n",
      "============================================================\n",
      "Total companies: 906\n",
      "Total disagreements: 3912\n",
      "Companies with disagreements: 592\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Find most recent company_stats file\n",
    "stats_files = glob.glob(VOTING_DATA_PATH + 'company_stats_251210_0705.csv')\n",
    "if stats_files:\n",
    "    latest_stats = max(stats_files, key=os.path.getctime)\n",
    "    print(f\"Loading: {latest_stats}\\n\")\n",
    "    df_stats_new = pd.read_csv(latest_stats)\n",
    "else:\n",
    "    print(\"No stats files found!\")\n",
    "\n",
    "# Check if we have tech companies now\n",
    "tech_companies = ['apple inc', 'microsoft corp', 'nvidia corp', 'alphabet inc', \n",
    "                  'meta platforms inc', 'amazon.com inc', 'broadcom inc', \n",
    "                  'tesla inc', 'asml holding nv', 'sap se']\n",
    "\n",
    "print(\"TECH GIANTS STATUS:\")\n",
    "print(\"=\"*60)\n",
    "for company in tech_companies:\n",
    "    if company in df_stats_new['company_name'].str.lower().values:\n",
    "        matches = df_stats_new[df_stats_new['company_name'].str.lower() == company]\n",
    "        if len(matches) > 0:\n",
    "            disagreements = matches.iloc[0]['total_disagreements']\n",
    "            print(f\"✅ {company:30} → {disagreements} disagreements\")\n",
    "    else:\n",
    "        print(f\"❌ {company:30} → NOT FOUND\")\n",
    "\n",
    "# Overall stats\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Total companies: {len(df_stats_new)}\")\n",
    "print(f\"Total disagreements: {df_stats_new['total_disagreements'].sum()}\")\n",
    "print(f\"Companies with disagreements: {(df_stats_new['total_disagreements'] > 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdc2574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUSTRY COVERAGE:\n",
      "============================================================\n",
      "                        N_companies  Total_disagreements  Avg_per_company\n",
      "Industry                                                                 \n",
      "Industrials                     179                  701              3.9\n",
      "Consumer Discretionary          146                  870              6.0\n",
      "Financials                      139                  522              3.8\n",
      "Technology                       90                  447              5.0\n",
      "Basic Materials                  82                  259              3.2\n",
      "Health Care                      73                  357              4.9\n",
      "Consumer Staples                 56                  235              4.2\n",
      "Real Estate                      53                  101              1.9\n",
      "Energy                           35                  229              6.5\n",
      "Utilities                        28                   96              3.4\n",
      "Telecommunications               25                   95              3.8\n",
      "\n",
      "============================================================\n",
      "TECH SECTOR DETAIL:\n",
      "Tech companies: 90\n",
      "Tech disagreements: 447\n",
      "Avg per tech company: 5.0\n",
      "\n",
      "\n",
      "TOP 10 TECH COMPANIES BY DISAGREEMENTS:\n",
      "                             company_name  total_disagreements\n",
      "332                          alphabet inc                   39\n",
      "370                           oracle corp                   36\n",
      "653                  dassault systemes se                   24\n",
      "419  international business machines corp                   21\n",
      "899                          wistron corp                   19\n",
      "856                           wiwynn corp                   18\n",
      "330                        microsoft corp                   17\n",
      "523                   te connectivity plc                   13\n",
      "751          united microelectronics corp                   13\n",
      "499                           naspers ltd                   12\n"
     ]
    }
   ],
   "source": [
    "# Merge with original df_p80 to get industry info\n",
    "df_analysis = df_stats.merge(\n",
    "    df_p80[['Name', 'Industry', 'Market_Value_USD', 'ESG_any']], \n",
    "    left_on='company_name', \n",
    "    right_on='Name', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"INDUSTRY COVERAGE:\")\n",
    "print(\"=\"*60)\n",
    "industry_stats = df_analysis.groupby('Industry').agg({\n",
    "    'company_name': 'count',\n",
    "    'total_disagreements': ['sum', 'mean']\n",
    "}).round(1)\n",
    "industry_stats.columns = ['N_companies', 'Total_disagreements', 'Avg_per_company']\n",
    "industry_stats = industry_stats.sort_values('N_companies', ascending=False)\n",
    "print(industry_stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TECH SECTOR DETAIL:\")\n",
    "tech = df_analysis[df_analysis['Industry'] == 'Technology']\n",
    "print(f\"Tech companies: {len(tech)}\")\n",
    "print(f\"Tech disagreements: {tech['total_disagreements'].sum()}\")\n",
    "print(f\"Avg per tech company: {tech['total_disagreements'].mean():.1f}\")\n",
    "\n",
    "print(\"\\n\\nTOP 10 TECH COMPANIES BY DISAGREEMENTS:\")\n",
    "print(tech.nlargest(10, 'total_disagreements')[['company_name', 'total_disagreements']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92940a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARKET VALUE COVERAGE:\n",
      "============================================================\n",
      "Companies coverage: 906/1925 (47.1%)\n",
      "Market value coverage: $710.9B / $1181.1B (60.2%)\n",
      "\n",
      "Top 100 companies: 66/100\n",
      "Top 500 companies: 281/500\n",
      "\n",
      "ESG_any companies: 473/901 (52.5%)\n",
      "\n",
      "============================================================\n",
      "ANALYZING 509 'NO DATA RETURNED' ERRORS:\n",
      "Average market value of failed: $0.61B\n",
      "Average market value of processed: $0.78B\n"
     ]
    }
   ],
   "source": [
    "# Check market value coverage\n",
    "df_p80['processed'] = df_p80['Name'].isin(df_stats['company_name'].tolist())\n",
    "\n",
    "total_market_value = df_p80['Market_Value_USD'].sum()\n",
    "processed_market_value = df_p80[df_p80['processed']]['Market_Value_USD'].sum()\n",
    "\n",
    "print(\"MARKET VALUE COVERAGE:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Companies coverage: {df_p80['processed'].sum()}/{len(df_p80)} ({df_p80['processed'].sum()/len(df_p80)*100:.1f}%)\")\n",
    "print(f\"Market value coverage: ${processed_market_value/1e9:.1f}B / ${total_market_value/1e9:.1f}B ({processed_market_value/total_market_value*100:.1f}%)\")\n",
    "\n",
    "# Check top companies coverage\n",
    "print(f\"\\nTop 100 companies: {df_p80.head(100)['processed'].sum()}/100\")\n",
    "print(f\"Top 500 companies: {df_p80.head(500)['processed'].sum()}/500\")\n",
    "\n",
    "# ESG_any coverage\n",
    "if 'ESG_any' in df_p80.columns:\n",
    "    esg_total = (df_p80['ESG_any'] == 1).sum()\n",
    "    esg_processed = df_p80[df_p80['processed'] & (df_p80['ESG_any'] == 1)].shape[0]\n",
    "    print(f\"\\nESG_any companies: {esg_processed}/{esg_total} ({esg_processed/esg_total*100:.1f}%)\")\n",
    "\n",
    "# Check the 509 \"No data returned\" - are they small companies?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYZING 509 'NO DATA RETURNED' ERRORS:\")\n",
    "failed_companies = df_errors[df_errors['error'] == 'No data returned']['company'].tolist()\n",
    "df_failed = df_p80[df_p80['Name'].isin(failed_companies)]\n",
    "print(f\"Average market value of failed: ${df_failed['Market_Value_USD'].mean()/1e9:.2f}B\")\n",
    "print(f\"Average market value of processed: ${df_p80[df_p80['processed']]['Market_Value_USD'].mean()/1e9:.2f}B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "789d49c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 30 MISSING COMPANIES BY MARKET VALUE:\n",
      "============================================================\n",
      "amazon.com inc                                     $  27.0B  Consumer Discretionary\n",
      "meta platforms inc                                 $  19.8B  Technology          \n",
      "taiwan semiconductor manufacturing co ltd          $  15.4B  Technology          \n",
      "tesla inc                                          $  14.2B  Consumer Discretionary\n",
      "eli lilly & co                                     $   8.3B  Health Care         \n",
      "jpmorgan chase & co                                $   8.2B  Financials          \n",
      "novo nordisk a/s                                   $   6.8B  Health Care         \n",
      "tencent holdings ltd                               $   6.7B  Technology          \n",
      "procter & gamble co/the                            $   5.2B  Consumer Staples    \n",
      "home depot inc/the                                 $   5.0B  Consumer Discretionary\n",
      "netflix inc                                        $   4.9B  Consumer Discretionary\n",
      "alibaba group holding ltd                          $   4.4B  Consumer Discretionary\n",
      "johnson & johnson                                  $   4.3B  Health Care         \n",
      "samsung electronics co ltd                         $   3.9B  Telecommunications  \n",
      "digital realty trust inc                           $   3.9B  Real Estate         \n",
      "salesforce inc                                     $   3.5B  Technology          \n",
      "nextera energy inc                                 $   3.5B  Utilities           \n",
      "merck & co inc                                     $   3.4B  Health Care         \n",
      "coca-cola co/the                                   $   3.4B  Consumer Staples    \n",
      "wells fargo & co                                   $   3.3B  Financials          \n",
      "cisco systems inc                                  $   3.2B  Telecommunications  \n",
      "advanced micro devices inc                         $   2.8B  Technology          \n",
      "pepsico inc                                        $   2.7B  Consumer Staples    \n",
      "servicenow inc                                     $   2.6B  Technology          \n",
      "intuitive surgical inc                             $   2.4B  Health Care         \n",
      "walt disney co/the                                 $   2.4B  Consumer Discretionary\n",
      "blackrock inc                                      $   2.3B  Financials          \n",
      "sanofi sa                                          $   2.2B  Health Care         \n",
      "caterpillar inc                                    $   2.1B  Industrials         \n",
      "mitsubishi ufj financial group inc                 $   2.1B  Financials          \n",
      "\n",
      "============================================================\n",
      "Combined market value: $179.7B\n",
      "Would increase coverage to: 75.4%\n",
      "\n",
      "Error breakdown for these 30:\n",
      "error\n",
      "No data returned    21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find top 30 unprocessed companies by market value\n",
    "df_unprocessed = df_p80[~df_p80['processed']].copy()\n",
    "top_30_missing = df_unprocessed.nlargest(30, 'Market_Value_USD')\n",
    "\n",
    "print(\"TOP 30 MISSING COMPANIES BY MARKET VALUE:\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in top_30_missing.iterrows():\n",
    "    print(f\"{row['Name']:50} ${row['Market_Value_USD']/1e9:6.1f}B  {row['Industry']:20}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Combined market value: ${top_30_missing['Market_Value_USD'].sum()/1e9:.1f}B\")\n",
    "print(f\"Would increase coverage to: {(processed_market_value + top_30_missing['Market_Value_USD'].sum())/total_market_value*100:.1f}%\")\n",
    "\n",
    "# Check which ones failed with \"No data returned\" vs rate limit\n",
    "top_30_names = top_30_missing['Name'].tolist()\n",
    "top_30_errors = df_errors[df_errors['company'].isin(top_30_names)]\n",
    "print(f\"\\nError breakdown for these 30:\")\n",
    "print(top_30_errors['error'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d3882fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR BREAKDOWN FOR TOP 30:\n",
      "============================================================\n",
      "error\n",
      "No data returned    21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total top 30 in errors: 21\n",
      "Missing from errors (might not have been attempted): 9\n"
     ]
    }
   ],
   "source": [
    "# Check what happened with ALL 30 top missing companies\n",
    "top_30_names = top_30_missing['Name'].tolist()\n",
    "top_30_errors = df_errors[df_errors['company'].isin(top_30_names)]\n",
    "\n",
    "print(\"ERROR BREAKDOWN FOR TOP 30:\")\n",
    "print(\"=\"*60)\n",
    "print(top_30_errors['error'].value_counts())\n",
    "\n",
    "print(f\"\\nTotal top 30 in errors: {len(top_30_errors)}\")\n",
    "print(f\"Missing from errors (might not have been attempted): {30 - len(top_30_errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f83b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 COMPANIES NOT ATTEMPTED:\n",
      "============================================================\n",
      "amazon.com inc                                     $  27.0B\n",
      "tesla inc                                          $  14.2B\n",
      "procter & gamble co/the                            $   5.2B\n",
      "home depot inc/the                                 $   5.0B\n",
      "netflix inc                                        $   4.9B\n",
      "alibaba group holding ltd                          $   4.4B\n",
      "coca-cola co/the                                   $   3.4B\n",
      "pepsico inc                                        $   2.7B\n",
      "walt disney co/the                                 $   2.4B\n",
      "\n",
      "\n",
      "Are they marked as 'already_processed'?\n",
      "amazon.com inc                                     → False\n",
      "tesla inc                                          → False\n",
      "procter & gamble co/the                            → False\n",
      "home depot inc/the                                 → False\n",
      "netflix inc                                        → False\n",
      "alibaba group holding ltd                          → False\n",
      "coca-cola co/the                                   → False\n",
      "pepsico inc                                        → False\n",
      "walt disney co/the                                 → False\n"
     ]
    }
   ],
   "source": [
    "# Check which 9 were not attempted\n",
    "top_30_names = top_30_missing['Name'].tolist()\n",
    "attempted_21 = top_30_errors['company'].tolist()\n",
    "not_attempted_9 = [name for name in top_30_names if name not in attempted_21]\n",
    "\n",
    "print(\"9 COMPANIES NOT ATTEMPTED:\")\n",
    "print(\"=\"*60)\n",
    "for name in not_attempted_9:\n",
    "    row = df_p80[df_p80['Name'] == name].iloc[0]\n",
    "    print(f\"{name:50} ${row['Market_Value_USD']/1e9:6.1f}B\")\n",
    "\n",
    "# Check if they were marked as processed or just skipped\n",
    "print(\"\\n\\nAre they marked as 'already_processed'?\")\n",
    "for name in not_attempted_9:\n",
    "    processed = df_p80[df_p80['Name'] == name]['already_processed'].iloc[0]\n",
    "    print(f\"{name:50} → {processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a52cf695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded stats: ../datasets/voting_data\\company_stats_20251210_0705.csv\n",
      "  Companies: 906\n",
      "  Total disagreements: 3912\n",
      "\n",
      "✓ Loaded disagreements: ../datasets/voting_data\\disagreements_20251210_0705.csv\n",
      "  Total rows: 3912\n",
      "\n",
      "✅ Data consistency check\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Find most recent files\n",
    "stats_files = glob.glob(VOTING_DATA_PATH + 'company_stats_*.csv')\n",
    "disagreements_files = glob.glob(VOTING_DATA_PATH + 'disagreements_*.csv')\n",
    "\n",
    "if stats_files:\n",
    "    latest_stats = max(stats_files, key=os.path.getctime)\n",
    "    df_stats_today = pd.read_csv(latest_stats)\n",
    "    print(f\"✓ Loaded stats: {latest_stats}\")\n",
    "    print(f\"  Companies: {len(df_stats_today)}\")\n",
    "    print(f\"  Total disagreements: {df_stats_today['total_disagreements'].sum()}\")\n",
    "\n",
    "if disagreements_files:\n",
    "    latest_disagreements = max(disagreements_files, key=os.path.getctime)\n",
    "    df_disagreements_today = pd.read_csv(latest_disagreements)\n",
    "    print(f\"\\n✓ Loaded disagreements: {latest_disagreements}\")\n",
    "    print(f\"  Total rows: {len(df_disagreements_today)}\")\n",
    "\n",
    "# Verify they match\n",
    "print(f\"\\n{'✅' if len(df_disagreements_today) == df_stats_today['total_disagreements'].sum() else '❌'} Data consistency check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0559f308",
   "metadata": {},
   "source": [
    "entregar: cuántas reuniones de cuántas empresas, en total total disagreements/total reuniones/ = por cada reunión, X tantos disagreements en promedio\n",
    "-sectores con mayor cantidad de disagreements\n",
    "-Position papers más usados\n",
    "-unirlo con ESG_any a ver qué onda\n",
    "-Clasificar en e, en s y en g? no sé si sea mucho pedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "379af1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 100 UNPROCESSED COMPANIES (search these manually in NBIM):\n",
      "======================================================================\n",
      "Rank  Company Name                                      Value (B)   Industry\n",
      "======================================================================\n",
      "1     amazon.com inc                                    $  27.0B    Consumer Discretionary\n",
      "2     meta platforms inc                                $  19.8B    Technology\n",
      "3     taiwan semiconductor manufacturing co ltd         $  15.4B    Technology\n",
      "4     tesla inc                                         $  14.2B    Consumer Discretionary\n",
      "5     eli lilly & co                                    $   8.3B    Health Care\n",
      "6     jpmorgan chase & co                               $   8.2B    Financials\n",
      "7     novo nordisk a/s                                  $   6.8B    Health Care\n",
      "8     tencent holdings ltd                              $   6.7B    Technology\n",
      "9     procter & gamble co/the                           $   5.2B    Consumer Staples\n",
      "10    home depot inc/the                                $   5.0B    Consumer Discretionary\n",
      "11    netflix inc                                       $   4.9B    Consumer Discretionary\n",
      "12    alibaba group holding ltd                         $   4.4B    Consumer Discretionary\n",
      "13    johnson & johnson                                 $   4.3B    Health Care\n",
      "14    samsung electronics co ltd                        $   3.9B    Telecommunications\n",
      "15    digital realty trust inc                          $   3.9B    Real Estate\n",
      "16    salesforce inc                                    $   3.5B    Technology\n",
      "17    nextera energy inc                                $   3.5B    Utilities\n",
      "18    merck & co inc                                    $   3.4B    Health Care\n",
      "19    coca-cola co/the                                  $   3.4B    Consumer Staples\n",
      "20    wells fargo & co                                  $   3.3B    Financials\n",
      "21    cisco systems inc                                 $   3.2B    Telecommunications\n",
      "22    advanced micro devices inc                        $   2.8B    Technology\n",
      "23    pepsico inc                                       $   2.7B    Consumer Staples\n",
      "24    servicenow inc                                    $   2.6B    Technology\n",
      "25    intuitive surgical inc                            $   2.4B    Health Care\n",
      "26    walt disney co/the                                $   2.4B    Consumer Discretionary\n",
      "27    blackrock inc                                     $   2.3B    Financials\n",
      "28    sanofi sa                                         $   2.2B    Health Care\n",
      "29    caterpillar inc                                   $   2.1B    Industrials\n",
      "30    mitsubishi ufj financial group inc                $   2.1B    Financials\n",
      "31    simon property group inc                          $   2.0B    Real Estate\n",
      "32    bhp group ltd                                     $   1.9B    Basic Materials\n",
      "33    progressive corp/the                              $   1.9B    Financials\n",
      "34    at&t inc                                          $   1.8B    Telecommunications\n",
      "35    dsv a/s                                           $   1.8B    Industrials\n",
      "36    lowe's cos inc                                    $   1.8B    Consumer Discretionary\n",
      "37    t-mobile us inc                                   $   1.8B    Telecommunications\n",
      "38    analog devices inc                                $   1.8B    Technology\n",
      "39    cie financiere richemont sa                       $   1.8B    Consumer Discretionary\n",
      "40    gilead sciences inc                               $   1.8B    Health Care\n",
      "41    sk hynix inc                                      $   1.8B    Technology\n",
      "42    recruit holdings co ltd                           $   1.7B    Industrials\n",
      "43    palantir technologies inc                         $   1.7B    Technology\n",
      "44    tjx cos inc/the                                   $   1.6B    Consumer Discretionary\n",
      "45    alexandria real estate equities inc               $   1.6B    Real Estate\n",
      "46    sumitomo mitsui financial group inc               $   1.6B    Financials\n",
      "47    goldman sachs group inc/the                       $   1.6B    Financials\n",
      "48    applied materials inc                             $   1.6B    Technology\n",
      "49    avalonbay communities inc                         $   1.5B    Real Estate\n",
      "50    uber technologies inc                             $   1.5B    Consumer Discretionary\n",
      "51    aia group ltd                                     $   1.5B    Financials\n",
      "52    eaton corp plc                                    $   1.5B    Industrials\n",
      "53    tokio marine holdings inc                         $   1.5B    Financials\n",
      "54    holcim ag                                         $   1.5B    Industrials\n",
      "55    icici bank ltd                                    $   1.4B    Financials\n",
      "56    micron technology inc                             $   1.4B    Technology\n",
      "57    fiserv inc                                        $   1.4B    Industrials\n",
      "58    kkr & co inc                                      $   1.4B    Financials\n",
      "59    arthur j gallagher & co                           $   1.4B    Financials\n",
      "60    apollo global management inc                      $   1.4B    Financials\n",
      "61    arista networks inc                               $   1.4B    Telecommunications\n",
      "62    shin-etsu chemical co ltd                         $   1.4B    Basic Materials\n",
      "63    sherwin-williams co/the                           $   1.3B    Industrials\n",
      "64    pnc financial services group inc/the              $   1.3B    Financials\n",
      "65    udr inc                                           $   1.3B    Real Estate\n",
      "66    charles schwab corp/the                           $   1.3B    Financials\n",
      "67    nintendo co ltd                                   $   1.3B    Consumer Discretionary\n",
      "68    sompo holdings inc                                $   1.2B    Financials\n",
      "69    deere & co                                        $   1.2B    Industrials\n",
      "70    marsh & mclennan cos inc                          $   1.2B    Financials\n",
      "71    cadence design systems inc                        $   1.2B    Technology\n",
      "72    mizuho financial group inc                        $   1.2B    Financials\n",
      "73    elevance health inc                               $   1.2B    Health Care\n",
      "74    mediatek inc                                      $   1.2B    Technology\n",
      "75    intercontinental exchange inc                     $   1.2B    Financials\n",
      "76    bharti airtel ltd                                 $   1.2B    Telecommunications\n",
      "77    anz group holdings ltd                            $   1.2B    Financials\n",
      "78    chubb ltd                                         $   1.1B    Financials\n",
      "79    bank of new york mellon corp/the                  $   1.1B    Financials\n",
      "80    nike inc                                          $   1.1B    Consumer Discretionary\n",
      "81    marvell technology inc                            $   1.1B    Technology\n",
      "82    fast retailing co ltd                             $   1.1B    Consumer Discretionary\n",
      "83    mondelez international inc                        $   1.1B    Consumer Staples\n",
      "84    chipotle mexican grill inc                        $   1.1B    Consumer Discretionary\n",
      "85    crowdstrike holdings inc                          $   1.1B    Technology\n",
      "86    ge vernova inc                                    $   1.1B    Industrials\n",
      "87    paypal holdings inc                               $   1.1B    Industrials\n",
      "88    motorola solutions inc                            $   1.1B    Telecommunications\n",
      "89    united parcel service inc                         $   1.1B    Industrials\n",
      "90    equinix inc                                       $   1.0B    Real Estate\n",
      "91    hon hai precision industry co ltd                 $   1.0B    Technology\n",
      "92    mitsui & co ltd                                   $   1.0B    Industrials\n",
      "93    charter communications inc                        $   1.0B    Telecommunications\n",
      "94    infosys ltd                                       $   1.0B    Technology\n",
      "95    muenchener rueckversicherungs-gesellschaft ag in muenchen$   1.0B    Financials\n",
      "96    anheuser-busch inbev sa/nv                        $   1.0B    Consumer Staples\n",
      "97    waste management inc                              $   1.0B    Utilities\n",
      "98    toronto-dominion bank/the                         $   1.0B    Financials\n",
      "99    moody's corp                                      $   1.0B    Financials\n",
      "100   palo alto networks inc                            $   1.0B    Technology\n",
      "======================================================================\n",
      "\n",
      "Total value: $274.1B\n",
      "\n",
      "✓ Saved to 'top_100_missing.csv' for reference\n"
     ]
    }
   ],
   "source": [
    "# Stop any running code first if needed\n",
    "# Then show the list\n",
    "\n",
    "# Get top 100 unprocessed companies\n",
    "df_unprocessed = df_p80[~df_p80['processed']].copy()\n",
    "top_100_missing = df_unprocessed.nlargest(100, 'Market_Value_USD')\n",
    "\n",
    "print(\"TOP 100 UNPROCESSED COMPANIES (search these manually in NBIM):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Rank':<6}{'Company Name':<50}{'Value (B)':<12}{'Industry'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for idx, (_, row) in enumerate(top_100_missing.iterrows(), 1):\n",
    "    name = row['Name']\n",
    "    value = row['Market_Value_USD'] / 1e9\n",
    "    industry = row['Industry']\n",
    "    print(f\"{idx:<6}{name:<50}${value:>6.1f}B    {industry}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal value: ${top_100_missing['Market_Value_USD'].sum()/1e9:.1f}B\")\n",
    "\n",
    "# Also save to CSV for easy reference\n",
    "top_100_missing[['Name', 'Market_Value_USD', 'Industry']].to_csv('top_100_missing.csv', index=False)\n",
    "print(\"\\n✓ Saved to 'top_100_missing.csv' for reference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333de8fa",
   "metadata": {},
   "source": [
    "# Manual mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d21d041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API setup complete\n"
     ]
    }
   ],
   "source": [
    "# Basic imports and API setup\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API credentials\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NBIM_API_KEY')\n",
    "BASE_URL = os.getenv('NBIM_BASE_URL')\n",
    "\n",
    "headers = {'x-api-key': API_KEY}\n",
    "\n",
    "print(\"✓ API setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43eae46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING MANUAL NBIM NAMES:\n",
      "======================================================================\n",
      "\n",
      "amazon.com inc\n",
      "  Testing: 'Amazon.com, Inc.'\n",
      "  ✅ FOUND: Ticker=AMZN, Meetings=13\n",
      "\n",
      "meta platforms inc\n",
      "  Testing: 'Meta Platforms, Inc.'\n",
      "  ✅ FOUND: Ticker=META, Meetings=13\n",
      "\n",
      "taiwan semiconductor manufacturing co ltd\n",
      "  Testing: 'Taiwan Semiconductor Manufacturing Co., Ltd.'\n",
      "  ✅ FOUND: Ticker=2330, Meetings=21\n",
      "\n",
      "tesla inc\n",
      "  Testing: 'Tesla, Inc.'\n",
      "  ✅ FOUND: Ticker=TSLA, Meetings=15\n",
      "\n",
      "eli lilly & co\n",
      "  Testing: 'Eli Lilly and Company'\n",
      "  ✅ FOUND: Ticker=LLY, Meetings=13\n",
      "\n",
      "jpmorgan chase & co\n",
      "  Testing: 'JPMorgan Chase & Co.'\n",
      "  ✅ FOUND: Ticker=JPM, Meetings=13\n",
      "\n",
      "======================================================================\n",
      "RESULTS:\n",
      "✅ Successful: 6/6\n",
      "❌ Failed: 0/6\n",
      "\n",
      "✓ These names work - you can continue finding the rest!\n"
     ]
    }
   ],
   "source": [
    "# Test the NBIM names you found manually\n",
    "test_mapping = {\n",
    "    'amazon.com inc': 'Amazon.com, Inc.',\n",
    "    'meta platforms inc': 'Meta Platforms, Inc.',\n",
    "    'taiwan semiconductor manufacturing co ltd': 'Taiwan Semiconductor Manufacturing Co., Ltd.',\n",
    "    'tesla inc': 'Tesla, Inc.',\n",
    "    'eli lilly & co': 'Eli Lilly and Company',\n",
    "    'jpmorgan chase & co': 'JPMorgan Chase & Co.'\n",
    "}\n",
    "\n",
    "print(\"TESTING MANUAL NBIM NAMES:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "successful = []\n",
    "failed = []\n",
    "\n",
    "for our_name, nbim_name in test_mapping.items():\n",
    "    print(f\"\\n{our_name}\")\n",
    "    print(f\"  Testing: '{nbim_name}'\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{BASE_URL}/v1/query/company/{nbim_name}\",\n",
    "            headers=headers,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'companies' in data and len(data['companies']) > 0:\n",
    "                company_info = data['companies'][0]\n",
    "                ticker = company_info.get('Ticker', 'N/A')\n",
    "                meetings = len(company_info.get('meetings', []))\n",
    "                print(f\"  ✅ FOUND: Ticker={ticker}, Meetings={meetings}\")\n",
    "                successful.append((our_name, nbim_name))\n",
    "            else:\n",
    "                print(f\"  ❌ No data returned\")\n",
    "                failed.append((our_name, nbim_name))\n",
    "        else:\n",
    "            print(f\"  ❌ Status {response.status_code}\")\n",
    "            failed.append((our_name, nbim_name))\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")\n",
    "        failed.append((our_name, nbim_name))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS:\")\n",
    "print(f\"✅ Successful: {len(successful)}/6\")\n",
    "print(f\"❌ Failed: {len(failed)}/6\")\n",
    "\n",
    "if successful:\n",
    "    print(\"\\n✓ These names work - you can continue finding the rest!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a978cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 100 companies...\n",
      "This will take ~5 minutes due to rate limiting\n",
      "\n",
      "  Progress: 20/100\n",
      "  Progress: 40/100\n",
      "  Progress: 60/100\n",
      "  Progress: 80/100\n",
      "  Progress: 100/100\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 136\u001b[0m\n\u001b[0;32m    133\u001b[0m         failed\u001b[38;5;241m.\u001b[39mappend(our_name)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Load df_p80 to calculate market value\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m df_p80 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp80_companies_sorted_with_status.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    137\u001b[0m successful_df \u001b[38;5;241m=\u001b[39m df_p80[df_p80[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(successful)]\n\u001b[0;32m    138\u001b[0m total_value \u001b[38;5;241m=\u001b[39m successful_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket_Value_USD\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Complete name mapping for top 100 companies\n",
    "name_mapping = {\n",
    "    'amazon.com inc': 'Amazon.com, Inc.',\n",
    "    'meta platforms inc': 'Meta Platforms, Inc.',\n",
    "    'taiwan semiconductor manufacturing co ltd': 'Taiwan Semiconductor Manufacturing Co., Ltd.',\n",
    "    'tesla inc': 'Tesla, Inc.',\n",
    "    'eli lilly & co': 'Eli Lilly and Company',\n",
    "    'jpmorgan chase & co': 'JPMorgan Chase & Co.',\n",
    "    'novo nordisk a/s': 'Novo Nordisk A/S',\n",
    "    'tencent holdings ltd': 'Tencent Holdings Limited',\n",
    "    'procter & gamble co/the': 'Procter & Gamble Health Limited',\n",
    "    'home depot inc/the': 'The Home Depot, Inc.',\n",
    "    'netflix inc': 'Netflix, Inc.',\n",
    "    'alibaba group holding ltd': 'Alibaba Group Holding Limited',\n",
    "    'johnson & johnson': 'Johnson & Johnson',\n",
    "    'samsung electronics co ltd': 'Samsung Electronics Co., Ltd.',\n",
    "    'digital realty trust inc': 'Digital Realty Trust, Inc.',\n",
    "    'salesforce inc': 'Salesforce, Inc.',\n",
    "    'nextera energy inc': 'NextEra Energy, Inc.',\n",
    "    'merck & co inc': 'Merck & Co., Inc.',\n",
    "    'coca-cola co/the': 'The Coca-Cola Company',\n",
    "    'wells fargo & co': 'Wells Fargo & Company',\n",
    "    'cisco systems inc': 'Cisco Systems, Inc.',\n",
    "    'advanced micro devices inc': 'Advanced Micro Devices, Inc.',\n",
    "    'pepsico inc': 'PepsiCo, Inc.',\n",
    "    'servicenow inc': 'ServiceNow, Inc.',\n",
    "    'intuitive surgical inc': 'Intuitive Surgical, Inc.',\n",
    "    'walt disney co/the': 'The Walt Disney Company',\n",
    "    'blackrock inc': 'BlackRock, Inc.',\n",
    "    'sanofi sa': 'Sanofi',\n",
    "    'caterpillar inc': 'Caterpillar, Inc.',\n",
    "    'mitsubishi ufj financial group inc': 'Mitsubishi UFJ Financial Group, Inc.',\n",
    "    'simon property group inc': 'Simon Property Group, Inc.',\n",
    "    'bhp group ltd': 'BHP Group (UK) Ltd.',\n",
    "    'progressive corp/the': 'The Progressive Corporation',\n",
    "    'at&t inc': 'AT&T Inc.',\n",
    "    'dsv a/s': 'DSV A/S',\n",
    "    \"lowe's cos inc\": 'Lowes Companies, Inc.',\n",
    "    't-mobile us inc': 'T-Mobile US, Inc.',\n",
    "    'analog devices inc': 'Analog Devices, Inc.',\n",
    "    'cie financiere richemont sa': 'Compagnie Financiere Richemont SA',\n",
    "    'gilead sciences inc': 'Gilead Sciences, Inc.',\n",
    "    'sk hynix inc': 'SK hynix, Inc.',\n",
    "    'recruit holdings co ltd': 'Recruit Holdings Co., Ltd.',\n",
    "    'palantir technologies inc': 'Palantir Technologies, Inc.',\n",
    "    'tjx cos inc/the': 'The TJX Companies, Inc.',\n",
    "    'alexandria real estate equities inc': 'Alexandria Real Estate Equities, Inc.',\n",
    "    'sumitomo mitsui financial group inc': 'Sumitomo Mitsui Trust Group, Inc.',\n",
    "    'goldman sachs group inc/the': 'The Goldman Sachs Group, Inc.',\n",
    "    'applied materials inc': 'Applied Materials, Inc.',\n",
    "    'avalonbay communities inc': 'AvalonBay Communities, Inc.',\n",
    "    'uber technologies inc': 'Uber Technologies, Inc.',\n",
    "    'aia group ltd': 'AIA Group Limited',\n",
    "    'eaton corp plc': 'Eaton Corporation plc',\n",
    "    'tokio marine holdings inc': 'Tokio Marine Holdings, Inc.',\n",
    "    'holcim ag': 'Holcim AG',\n",
    "    'icici bank ltd': 'ICICI Bank Limited',\n",
    "    'micron technology inc': 'Micron Technology, Inc.',\n",
    "    'fiserv inc': 'Fiserv, Inc.',\n",
    "    'kkr & co inc': 'KKR Real Estate Finance Trust Inc.',\n",
    "    'arthur j gallagher & co': 'Arthur J. Gallagher & Co.',\n",
    "    'apollo global management inc': 'Apollo Global Management, Inc.',\n",
    "    'arista networks inc': 'Arista Networks, Inc.',\n",
    "    'shin-etsu chemical co ltd': 'Shin-Etsu Polymer Co., Ltd.',\n",
    "    'sherwin-williams co/the': 'The Sherwin-Williams Company',\n",
    "    'pnc financial services group inc/the': 'The PNC Financial Services Group, Inc.',\n",
    "    'udr inc': 'UDR, Inc.',\n",
    "    'charles schwab corp/the': 'The Charles Schwab Corporation',\n",
    "    'nintendo co ltd': 'Nintendo Co., Ltd.',\n",
    "    'sompo holdings inc': 'Sompo Holdings, Inc.',\n",
    "    'deere & co': 'Deere & Company',\n",
    "    'marsh & mclennan cos inc': 'Marsh & McLennan Companies, Inc.',\n",
    "    'cadence design systems inc': 'Cadence Design Systems, Inc.',\n",
    "    'mizuho financial group inc': 'Mizuho Financial Group, Inc.',\n",
    "    'elevance health inc': 'Elevance Health, Inc.',\n",
    "    'mediatek inc': 'MediaTek, Inc.',\n",
    "    'intercontinental exchange inc': 'Intercontinental Exchange, Inc.',\n",
    "    'bharti airtel ltd': 'Bharti Hexacom Ltd.',\n",
    "    'anz group holdings ltd': 'ANZ Group Holdings Limited',\n",
    "    'chubb ltd': 'Chubb Limited',\n",
    "    'bank of new york mellon corp/the': 'The Bank of New York Mellon Corporation',\n",
    "    'nike inc': 'NIKE, Inc.',\n",
    "    'marvell technology inc': 'Marvell Technology, Inc.',\n",
    "    'fast retailing co ltd': 'Fast Retailing Co., Ltd.',\n",
    "    'mondelez international inc': 'Mondelez International, Inc.',\n",
    "    'chipotle mexican grill inc': 'Chipotle Mexican Grill, Inc.',\n",
    "    'crowdstrike holdings inc': 'CrowdStrike Holdings, Inc.',\n",
    "    'ge vernova inc': 'GE Vernova, Inc.',\n",
    "    'paypal holdings inc': 'PayPal Holdings, Inc.',\n",
    "    'motorola solutions inc': 'Motorola Solutions, Inc.',\n",
    "    'united parcel service inc': 'United Parcel Service, Inc.',\n",
    "    'equinix inc': 'Equinix, Inc.',\n",
    "    'hon hai precision industry co ltd': 'Hon Hai Precision Industry Co., Ltd.',\n",
    "    'mitsui & co ltd': 'Mitsui & Co., Ltd.',\n",
    "    'charter communications inc': 'Charter Communications, Inc.',\n",
    "    'infosys ltd': 'Infosys Limited',\n",
    "    'muenchener rueckversicherungs-gesellschaft ag in muenchen': 'Muenchener Rueckversicherungs-Gesellschaft AG',\n",
    "    'anheuser-busch inbev sa/nv': 'Anheuser-Busch InBev SA/NV',\n",
    "    'waste management inc': 'Waste Management, Inc.',\n",
    "    'toronto-dominion bank/the': 'The Toronto-Dominion Bank',\n",
    "    \"moody's corp\": 'Moodys Corporation',\n",
    "    'palo alto networks inc': 'Palo Alto Networks, Inc.',\n",
    "}\n",
    "\n",
    "print(f\"Testing {len(name_mapping)} companies...\")\n",
    "print(\"This will take ~5 minutes due to rate limiting\\n\")\n",
    "\n",
    "successful = []\n",
    "failed = []\n",
    "\n",
    "for idx, (our_name, nbim_name) in enumerate(name_mapping.items(), 1):\n",
    "    if idx % 20 == 0:\n",
    "        print(f\"  Progress: {idx}/{len(name_mapping)}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{BASE_URL}/v1/query/company/{nbim_name}\",\n",
    "            headers=headers,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'companies' in data and len(data['companies']) > 0:\n",
    "                successful.append(our_name)\n",
    "            else:\n",
    "                failed.append(our_name)\n",
    "        else:\n",
    "            failed.append(our_name)\n",
    "        \n",
    "        time.sleep(0.3)\n",
    "    except:\n",
    "        failed.append(our_name)\n",
    "\n",
    "# Load df_p80 to calculate market value\n",
    "df_p80 = pd.read_csv(DATA_PATH + 'p80_companies_sorted_with_status.csv')\n",
    "successful_df = df_p80[df_p80['Name'].isin(successful)]\n",
    "total_value = successful_df['Market_Value_USD'].sum()\n",
    "\n",
    "# Check for key big tech\n",
    "big_tech = ['amazon.com inc', 'meta platforms inc', 'tesla inc']\n",
    "big_tech_recovered = [name for name in big_tech if name in successful]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"✅ Successful: {len(successful)}/{len(name_mapping)} ({len(successful)/len(name_mapping)*100:.1f}%)\")\n",
    "print(f\"❌ Failed: {len(failed)}/{len(name_mapping)}\")\n",
    "print(f\"\\n💰 Total market value covered: ${total_value/1e9:.1f}B\")\n",
    "print(f\"\\n🎯 Big Tech recovered:\")\n",
    "for name in big_tech:\n",
    "    status = \"✅\" if name in big_tech_recovered else \"❌\"\n",
    "    print(f\"  {status} {name}\")\n",
    "\n",
    "if failed:\n",
    "    print(f\"\\n❌ Failed companies ({len(failed)}):\")\n",
    "    for name in failed[:10]:\n",
    "        print(f\"  - {name}\")\n",
    "    if len(failed) > 10:\n",
    "        print(f\"  ... and {len(failed)-10} more\")\n",
    "\n",
    "# Save successful mapping\n",
    "successful_mapping = {k: v for k, v in name_mapping.items() if k in successful}\n",
    "with open('manual_name_mapping.json', 'w') as f:\n",
    "    json.dump(successful_mapping, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Saved {len(successful_mapping)} confirmed mappings to 'manual_name_mapping.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3345a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API credentials\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NBIM_API_KEY')\n",
    "BASE_URL = os.getenv('NBIM_BASE_URL')\n",
    "headers = {'x-api-key': API_KEY}\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../datasets/\"\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83464e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL RESULTS:\n",
      "======================================================================\n",
      "✅ Successful: 96/100 (96.0%)\n",
      "❌ Failed: 4/100\n",
      "\n",
      "💰 Total market value covered: $263.1B\n",
      "\n",
      "🎯 Big Tech recovered:\n",
      "  ✅ amazon.com inc\n",
      "  ✅ meta platforms inc\n",
      "  ✅ tesla inc\n",
      "\n",
      "❌ Failed companies (4):\n",
      "  - novo nordisk a/s\n",
      "  - dsv a/s\n",
      "  - holcim ag\n",
      "  - anheuser-busch inbev sa/nv\n",
      "\n",
      "✓ Saved 96 confirmed mappings to 'manual_name_mapping.json'\n"
     ]
    }
   ],
   "source": [
    "# Load df_p80 to calculate market value\n",
    "df_p80 = pd.read_csv(DATA_PATH + 'p80_companies_sorted_with_status.csv')\n",
    "successful_df = df_p80[df_p80['Name'].isin(successful)]\n",
    "total_value = successful_df['Market_Value_USD'].sum()\n",
    "\n",
    "# Check for key big tech\n",
    "big_tech = ['amazon.com inc', 'meta platforms inc', 'tesla inc']\n",
    "big_tech_recovered = [name for name in big_tech if name in successful]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"✅ Successful: {len(successful)}/{len(name_mapping)} ({len(successful)/len(name_mapping)*100:.1f}%)\")\n",
    "print(f\"❌ Failed: {len(failed)}/{len(name_mapping)}\")\n",
    "print(f\"\\n💰 Total market value covered: ${total_value/1e9:.1f}B\")\n",
    "print(f\"\\n🎯 Big Tech recovered:\")\n",
    "for name in big_tech:\n",
    "    status = \"✅\" if name in big_tech_recovered else \"❌\"\n",
    "    print(f\"  {status} {name}\")\n",
    "\n",
    "if failed:\n",
    "    print(f\"\\n❌ Failed companies ({len(failed)}):\")\n",
    "    for name in failed[:10]:\n",
    "        print(f\"  - {name}\")\n",
    "    if len(failed) > 10:\n",
    "        print(f\"  ... and {len(failed)-10} more\")\n",
    "\n",
    "# Save successful mapping\n",
    "successful_mapping = {k: v for k, v in name_mapping.items() if k in successful}\n",
    "with open('manual_name_mapping.json', 'w') as f:\n",
    "    json.dump(successful_mapping, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Saved {len(successful_mapping)} confirmed mappings to 'manual_name_mapping.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b450a",
   "metadata": {},
   "source": [
    "# Check the cell above and then continue with the extraction with the cells beneath, it will run for a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Delete temp checkpoints from today's run\n",
    "temp_files = ['./temp/checkpoint_progress.csv', \n",
    "              './temp/checkpoint_disagreements.csv', \n",
    "              './temp/checkpoint_stats.csv']\n",
    "\n",
    "for file in temp_files:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"✓ Deleted {file}\")\n",
    "\n",
    "print(\"\\nReady for fresh run tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SETUP: Paths and imports\n",
    "#It has all the imports as it was from scratch\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API credentials\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NBIM_API_KEY')\n",
    "BASE_URL = os.getenv('NBIM_BASE_URL')\n",
    "\n",
    "headers = {'x-api-key': API_KEY}\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../datasets/\"\n",
    "TEMP_PATH = \"./temp/\"\n",
    "VOTING_DATA_PATH = \"../datasets/voting_data/\"\n",
    "\n",
    "# Create directories if needed\n",
    "os.makedirs(TEMP_PATH, exist_ok=True)\n",
    "os.makedirs(VOTING_DATA_PATH, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Load sorted df_p80 with processing status\n",
    "df_p80 = pd.read_csv(DATA_PATH + 'p80_companies_sorted_with_status.csv')\n",
    "\n",
    "# Filter only unprocessed companies\n",
    "df_to_process = df_p80[~df_p80['already_processed']].copy()\n",
    "\n",
    "print(f\"Total companies in sample: {len(df_p80)}\")\n",
    "print(f\"Already processed: {df_p80['already_processed'].sum()}\")\n",
    "print(f\"To process today: {len(df_to_process)}\")\n",
    "print(f\"\\nStarting with: {df_to_process.iloc[0]['Name']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def clean_company_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = re.sub(r'[.,()&/]', '', name)\n",
    "    name = ' '.join(name.split())\n",
    "    return name.strip()\n",
    "\n",
    "# =============================================================================\n",
    "# CHECKPOINT SETUP\n",
    "# =============================================================================\n",
    "\n",
    "checkpoint_file = TEMP_PATH + 'checkpoint_progress.csv'\n",
    "disagreements_file = TEMP_PATH + 'checkpoint_disagreements.csv'\n",
    "stats_file = TEMP_PATH + 'checkpoint_stats.csv'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    processed_companies = pd.read_csv(checkpoint_file)['company_name'].tolist()\n",
    "    all_disagreements = pd.read_csv(disagreements_file).to_dict('records')\n",
    "    company_stats = pd.read_csv(stats_file).to_dict('records')\n",
    "    print(f\"\\n✓ RESUMING from checkpoint: {len(processed_companies)} companies in this session\")\n",
    "else:\n",
    "    processed_companies = []\n",
    "    all_disagreements = []\n",
    "    company_stats = []\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXTRACTION LOOP\n",
    "# =============================================================================\n",
    "\n",
    "start_time = datetime.now()\n",
    "processed = len(processed_companies)\n",
    "errors = []\n",
    "checkpoint_interval = 100\n",
    "\n",
    "for idx, row in df_to_process.iterrows():\n",
    "    company_name = row['Name']\n",
    "    ticker = row.get('Ticker', '')\n",
    "    \n",
    "    # Skip if already processed in this session\n",
    "    if company_name in processed_companies:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    \n",
    "    # Progress update every 50 companies\n",
    "    if processed % 50 == 0:\n",
    "        elapsed = (datetime.now() - start_time).seconds\n",
    "        rate = processed / (elapsed + 1)\n",
    "        remaining = (len(df_to_process) - processed) / rate / 60\n",
    "        print(f\"Progress: {processed}/{len(df_to_process)} ({processed/len(df_to_process)*100:.1f}%) - Est. {remaining:.1f} min remaining\")\n",
    "    \n",
    "    try:\n",
    "        response = None\n",
    "        \n",
    "        # Try 1: Search by ticker\n",
    "        if ticker and ticker.strip():\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/ticker/{ticker}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200 and 'companies' in response.json() and len(response.json()['companies']) > 0:\n",
    "                pass\n",
    "            else:\n",
    "                response = None\n",
    "        \n",
    "        # Try 2: Search by company name\n",
    "        if response is None:\n",
    "            clean_name = clean_company_name(company_name)\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/company/{clean_name}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "        \n",
    "        # If both failed, log error and continue\n",
    "        if response.status_code != 200:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': f'Status {response.status_code}'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_data = response.json()\n",
    "        \n",
    "        # Check if companies array exists\n",
    "        if 'companies' not in company_data or len(company_data['companies']) == 0:\n",
    "            errors.append({'company': company_name, 'ticker': ticker, 'error': 'No data returned'})\n",
    "            processed_companies.append(company_name)\n",
    "            continue\n",
    "        \n",
    "        company_info = company_data['companies'][0]\n",
    "        meetings = company_info.get('meetings', [])\n",
    "        \n",
    "        # Filter meetings from 2020 onwards\n",
    "        meetings_2020_plus = [\n",
    "            m for m in meetings \n",
    "            if datetime.strptime(m['meetingDate'], '%Y-%m-%d %H:%M:%S').year >= 2020\n",
    "        ]\n",
    "        \n",
    "        total_disagreements = 0\n",
    "        \n",
    "        # Process each meeting\n",
    "        for meeting in meetings_2020_plus:\n",
    "            meeting_id = meeting['meetingId']\n",
    "            meeting_date = meeting['meetingDate']\n",
    "            \n",
    "            # Rate limiting: 1 second delay\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "            meeting_response = requests.get(\n",
    "                f\"{BASE_URL}/v1/query/meeting/{meeting_id}\",\n",
    "                headers=headers,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if meeting_response.status_code != 200:\n",
    "                continue\n",
    "            \n",
    "            meeting_data = meeting_response.json()\n",
    "            votes = meeting_data.get('meeting', {}).get('meetingVotes', [])\n",
    "            \n",
    "            # Identify disagreements\n",
    "            for vote in votes:\n",
    "                mgmt_rec = vote.get('managementRec', '')\n",
    "                nbim_vote = vote.get('voteInstruction', '')\n",
    "                \n",
    "                # SKIP if management_rec is None, empty, or string \"None\"\n",
    "                if mgmt_rec is None or mgmt_rec == '' or pd.isna(mgmt_rec) or str(mgmt_rec) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                # SKIP if nbim_vote is None, empty, or string \"None\"\n",
    "                if nbim_vote is None or nbim_vote == '' or pd.isna(nbim_vote) or str(nbim_vote) == 'None':\n",
    "                    continue\n",
    "                \n",
    "                # DISAGREEMENT: when different\n",
    "                if mgmt_rec != nbim_vote:\n",
    "                    total_disagreements += 1\n",
    "                    \n",
    "                    # Extract rationale info\n",
    "                    rationale_info = vote.get('voterRationale', None)\n",
    "                    position_paper = ''\n",
    "                    rationale_text = ''\n",
    "                    \n",
    "                    if rationale_info and len(rationale_info) > 0:\n",
    "                        position_paper = rationale_info[0].get('positionPaper', {}).get('name', '')\n",
    "                        rationale_text = rationale_info[0].get('publicRationaleOutgoing', '')\n",
    "                    \n",
    "                    # Store disagreement\n",
    "                    all_disagreements.append({\n",
    "                        'company_name': company_name,\n",
    "                        'ticker': company_info.get('Ticker', ''),\n",
    "                        'country': company_info.get('country', ''),\n",
    "                        'meeting_date': meeting_date,\n",
    "                        'meeting_id': meeting_id,\n",
    "                        'meeting_type': meeting.get('meetingType', ''),\n",
    "                        'proposal_number': vote.get('proposalNumber', ''),\n",
    "                        'proposal_text': vote.get('proposalText', ''),\n",
    "                        'proponent': vote.get('proponent', ''),\n",
    "                        'management_rec': mgmt_rec,\n",
    "                        'nbim_vote': nbim_vote,\n",
    "                        'position_paper': position_paper,\n",
    "                        'rationale_text': rationale_text\n",
    "                    })\n",
    "        \n",
    "        # Store company-level stats\n",
    "        company_stats.append({\n",
    "            'company_name': company_name,\n",
    "            'ticker': company_info.get('Ticker', ''),\n",
    "            'total_meetings_2020_plus': len(meetings_2020_plus),\n",
    "            'total_disagreements': total_disagreements\n",
    "        })\n",
    "        \n",
    "        processed_companies.append(company_name)\n",
    "        \n",
    "        # CHECKPOINT: Save progress every 100 companies\n",
    "        if len(processed_companies) % checkpoint_interval == 0:\n",
    "            pd.DataFrame({'company_name': processed_companies}).to_csv(checkpoint_file, index=False)\n",
    "            pd.DataFrame(all_disagreements).to_csv(disagreements_file, index=False)\n",
    "            pd.DataFrame(company_stats).to_csv(stats_file, index=False)\n",
    "            print(f\"\\n✓ Checkpoint saved at {len(processed_companies)} companies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append({'company': company_name, 'ticker': ticker, 'error': str(e)})\n",
    "        processed_companies.append(company_name)\n",
    "        continue\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SAVE\n",
    "# =============================================================================\n",
    "\n",
    "df_disagreements = pd.DataFrame(all_disagreements)\n",
    "df_stats = pd.DataFrame(company_stats)\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "# Save to voting_data folder with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "df_disagreements.to_csv(VOTING_DATA_PATH + f'disagreements_{timestamp}.csv', index=False)\n",
    "df_stats.to_csv(VOTING_DATA_PATH + f'company_stats_{timestamp}.csv', index=False)\n",
    "df_errors.to_csv(VOTING_DATA_PATH + f'errors_{timestamp}.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total companies processed in this session: {processed}\")\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "print(f\"Total disagreements found: {len(df_disagreements)}\")\n",
    "print(f\"\\nCompanies with disagreements: {(df_stats['total_disagreements'] > 0).sum()}\")\n",
    "print(f\"Companies with zero disagreements: {(df_stats['total_disagreements'] == 0).sum()}\")\n",
    "print(f\"\\nData saved to: {VOTING_DATA_PATH}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# UPDATE P80 STATUS AFTER EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "# Load latest stats to see which companies were processed\n",
    "stats_files = glob.glob(VOTING_DATA_PATH + 'company_stats_*.csv')\n",
    "latest_stats = max(stats_files, key=os.path.getctime)\n",
    "df_stats_final = pd.read_csv(latest_stats)\n",
    "\n",
    "# Update df_p80 with newly processed companies\n",
    "newly_processed = df_stats_final['company_name'].tolist()\n",
    "df_p80['already_processed'] = df_p80['Name'].isin(newly_processed)\n",
    "\n",
    "# Save updated df_p80\n",
    "df_p80.to_csv(DATA_PATH + 'p80_companies_sorted_with_status.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UPDATED P80 STATUS FILE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Companies marked as processed: {df_p80['already_processed'].sum()}\")\n",
    "print(f\"Companies remaining: {(~df_p80['already_processed']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2108a",
   "metadata": {},
   "source": [
    "añade corporate sustainability junto con  shareholders proposals on sustainability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
